# 🎯 エネルギー予測システム フロー設計書・自動化ロードマップ

## 📋 システム概要

**目的**: 毎日自動で電力予測を実行し、Looker Studioで公開可能なダッシュボードシステム構築  
**実行環境**: ローカルPC（Windows + VS Code + venv） → クラウド自動化移行予定  
**データ基盤**: GCP（BigQuery + GCS）  
**可視化**: Looker Studio（公開ダッシュボード）  
**予測精度**: MAPE 3.13%（Phase 11準備完了・CSV出力対応済み）  
**⚠️ API制限対応**: Open-Meteo制限により16日間予測に調整
**最終更新**: 2025-09-03 Phase 11 Looker Studio構築準備完了時点

---

## 🔄 自動化パイプライン設計（4段階構成）

### **現在の手動フロー → 完全自動化への移行計画**

**目標**: 手動実行 → 完全自動化による運用レベルシステム構築

```
段階①: 電力・天気データ → GCS自動アップロード
段階②: GCP SQL処理 → 前処理済みデータ出力  
段階③: ローカル予測実行 → BigQueryからDL → 予測
段階④: 予測結果アップロード → Looker Studio自動更新
```

## 📊 自動化実装状況マトリクス

**現在日時**: 2025-09-03  
**Phase**: 11 Looker Studio構築準備

| 段階 | 処理内容 | 現在の実装状況 | 新規作成必要 | 優先度 | 技術課題 |
|-----|---------|---------------|-------------|-------|----------|
| ① | データ自動取得・GCS | 既存コード完備✅ | Cloud Scheduler設定 | 高 | 認証・エラーハンドリング |
| ② | BigQuery SQL処理 | 部分的実装✅ | Scheduled Queries設定 | 高 | 特徴量生成SQL化 |
| ③ | 予測実行・データDL | 既存コード完備✅ | BigQueryからDL機能 | 中 | ローカル自動実行 |
| ④ | 結果UP・可視化 | 部分的実装✅ | Looker Studio構築 | **進行中** | ダッシュボード設計 |

---

## 📊 段階① データ自動取得・GCSアップロード設計

### **自動化アーキテクチャ**
- **現在**: 手動実行（`data_downloader.py` + `gcs_uploader.py`）
- **目標**: Cloud Scheduler → Cloud Functions → 完全自動実行
- **実行頻度**: 日次朝8時（東京電力データ更新タイミング考慮）

### **電力データ取得**
- **データソース**: 東京電力 TEPCO API
- **取得期間**: 昨日分（24時間分）
- **データ形式**: ZIP形式 → CSV抽出
- **保存先**: ローカル一時ディレクトリ
- **データ項目**: 日付、時刻、実績電力消費量、供給力

### **気象データ取得（Phase 10 WeatherDownloader）**
- **データソース**: Open-Meteo API
- **取得地点**: 千葉県（Phase 9で最重要地点として確定）
- **Historical API**: 昨日分実績データ（archive-api）
- **Forecast API**: 16日間予測データ（api制限対応）
- **保存先**: ローカル一時ディレクトリ
- **データ項目**: 日付、時刻、気温、湿度、降水量、天気コード

### **エラーハンドリング考慮事項**
- **404エラー**: データ未公開時（土日・祝日後）の対応
- **API制限**: レート制限時の待機・リトライ機能
- **通信エラー**: タイムアウト・接続エラー時の復旧処理
- **データ異常**: 欠損値・異常値の検出・品質チェック

---

## 🔧 段階② BigQuery SQL処理・前処理データマート構築

### **現在の実装状況**
- **接続機能**: `weather_bigquery_loader.py` ✅
- **データ結合**: 電力・天気の統合テーブル ✅
- **特徴量生成**: Python処理（ローカル） ✅

### **自動化が必要な処理**
- **BigQuery Scheduled Queries**: 特徴量生成SQLの定期実行
- **データマート作成**: 予測用最適化テーブル設計
- **品質監視**: 欠損値・外れ値の自動検出アラート

### **SQL処理内容詳細**
```sql
-- 特徴量生成処理（自動化対象）
CREATE OR REPLACE TABLE `project.dataset.ml_features_processed` AS
SELECT 
  date_hour,
  power_consumption,
  LAG(power_consumption, 1) OVER (ORDER BY date_hour) as lag_1_business_day,
  temperature_2m,
  COS(2 * PI() * EXTRACT(HOUR FROM date_hour) / 24) as hour_cos,
  SIN(2 * PI() * EXTRACT(HOUR FROM date_hour) / 24) as hour_sin,
  CASE WHEN EXTRACT(DAYOFWEEK FROM date_hour) IN (1,7) THEN 1 ELSE 0 END as is_weekend,
  -- その他Phase 9確定の12特徴量
FROM `project.dataset.power_weather_integrated`
WHERE date_hour >= CURRENT_DATE() - INTERVAL 30 DAY
```

### **出力データ形式**
- **テーブル名**: `ml_features_processed`
- **更新頻度**: 日次（新データ投入後）
- **保持期間**: 予測用30日分 + 履歴データ

### **生データの永続保存**
- **電力データ**: GCSバケットの日付別ディレクトリに保存
- **気象データ**: GCSバケットの日付別ディレクトリに保存
- **重複チェック**: 同日データ存在時の上書き処理
- **メタデータ**: アップロード日時・データサイズ・品質情報記録

### **目的**
- 生データのバックアップ・履歴管理
- 将来的なデータ再処理・分析への備え
- システム障害時の復旧用データ確保

---

## 🤖 段階③ 予測実行・BigQueryデータ連携

### **現在の実装状況**
- **予測エンジン**: `prediction_iterative_with_export.py` ✅
- **モデル**: XGBoost・段階的予測・MAPE 3.13%達成 ✅
- **出力形式**: CSV 8列構造・384時間分データ ✅

### **自動化が必要な機能**
- **BigQueryからデータ取得**: `ml_features_processed`テーブルからのDL
- **ローカル自動実行**: Windows Task Scheduler設定
- **結果検証**: 実績値との比較・精度アラート機能

### **実行仕様詳細**
```python
# BigQueryデータ取得（新規実装必要）
def fetch_prediction_data_from_bigquery():
    query = """
    SELECT * FROM `project.dataset.ml_features_processed`
    WHERE date_hour >= CURRENT_DATE() - INTERVAL 30 DAY
    ORDER BY date_hour
    """
    return client.query(query).to_dataframe()

# 実行頻度: 日次（データ更新後）
# 予測期間: 16日間・時間別詳細
# 品質保証: MAPE閾値監視・異常検知
```

### **出力データ構造（確定版）**
| カラム名 | 内容 | 例 |
|---------|------|-----|
| `target_date` | 予測対象日 | 2025-06-01 |
| `target_hour` | 予測対象時刻 | 0 |
| `predicted_power` | 予測値(万kW) | 2154.15 |
| `actual_power` | 実績値(万kW) | 2131.00 |
| `error_absolute` | 絶対誤差(万kW) | 23.15 |
| `error_percentage` | 誤差率(%) | 1.09 |
| `target_weekday` | 曜日（0=月曜） | 6 |
| `target_is_weekend` | 週末フラグ | 1 |

### **BigQueryでの統合処理**
- **Step 1**: GCSからBigQueryへのデータ投入
- **Step 2**: Phase 5-6で確立した特徴量生成ロジックの実行
- **Step 3**: 予測用データセットの準備・ローカルダウンロード

### **生成される特徴量（Phase 10確定版）**
- **lag_1_business_day**: 1営業日前データ（重要度84.3%・土日祝日欠損対応済み）
- **temperature_2m**: 気温（重要度7.2%）
- **時間周期性**: hour_cos, hour_sin
- **カレンダー**: is_weekend, is_holiday, month
- **その他**: 計12特徴量（Phase 9で精度検証済み・Phase 10土日祝日対応確認済み）

### **データ期間**
- 予測に必要な過去データ（営業日ラグ計算のため約30日分）
- 最新データを含む時系列データセット

---

## 📈 段階④ 予測結果アップロード・Looker Studio自動更新

### **現在の実装状況**
- **アップロード機能**: `gcs_uploader.py` ✅（流用可能）
- **データ形式**: 予測値・実績値・誤差・メタデータ ✅
- **CSV出力**: 8列構造・BigQuery投入準備完了 ✅

### **Looker Studio構築要件**
- **データソース**: BigQuery `prediction_results`テーブル
- **更新方式**: 新データ挿入時の自動更新
- **アクセス設定**: 一般公開URL（ポートフォリオ用）

### **ダッシュボード仕様詳細**
#### **時系列チャート**
- 予測値vs実績値の16日間推移
- 日別・時間別の切り替え表示
- 信頼区間・誤差バンドの表示

#### **精度監視パネル**
- MAPE・MAE・RMSE等の統計指標
- 日別誤差率の推移グラフ
- 外れ値・異常値の検出表示

#### **統計分析セクション**
- 曜日別・時間帯別の予測精度分析
- 季節性・トレンド分析
- モデル性能の継続監視

#### **インタラクティブ機能**
- 期間選択フィルタ
- データ種別切り替え（予測/実績/誤差）
- ドリルダウン機能（日→時間→詳細）

### **BigQuery予測結果テーブル設計**
```sql
CREATE TABLE `project.dataset.prediction_results` (
  prediction_run_date DATE,
  target_date DATE,
  target_hour INT64,
  predicted_power FLOAT64,
  actual_power FLOAT64,
  error_absolute FLOAT64,
  error_percentage FLOAT64,
  target_weekday INT64,
  target_is_weekend INT64,
  created_at TIMESTAMP,
  model_version STRING
)
```

### **XGBoost予測エンジン（Phase 10土日祝日対応版）**
- **使用モデル**: Phase 9で学習完了したXGBoostモデル
- **予測精度**: MAPE 2.54%（土日祝日欠損値込み・実証済み）
- **欠損値処理**: XGBoost自動処理（dropna()なし・全曜日対応）
- **入力データ**: 特徴量生成フェーズで準備されたデータセット

### **予測期間設定（API制限対応）**
- **16日間予測**: 今日から16日後まで（384時間分）- Open-Meteo API制限対応
- **段階的予測**: lagを予測値で埋めていく実運用シミュレーション
- **品質保証**: 日別・曜日別・時系列分析による多角的検証

### **予測処理内容**
- **土日祝日対応**: 欠損値自動処理による全曜日統一モデル
- **12特徴量**: Phase 9確定・Phase 10土日祝日検証済み
- **予測値・信頼区間・メタデータ生成**

### **出力データ形式**
- 予測実行日、予測対象日時、予測値
- 予測タイプ（16日間）、モデルバージョン
- 信頼区間、品質指標

---

## ⚙️ 自動化実装の優先順位・依存関係

### **Phase別自動化ロードマップ**

#### **Phase 11**: ④Looker Studio完成（現在進行中）
- **目標**: 手動データでダッシュボード構築完了
- **成果**: データ形式・表示要件の確定
- **期間**: 2025年9月（現在）

#### **Phase 12**: ①データ取得自動化
- **実装内容**: Cloud Scheduler + Cloud Functions
- **技術課題**: GCP認証・エラーハンドリング・ログ管理
- **期待効果**: 安定したデータ供給の確保
- **コスト**: $5-10/月程度

#### **Phase 13**: ②③予測パイプライン統合自動化
- **実装内容**: BigQuery ↔ ローカル予測の自動連携
- **技術課題**: 特徴量生成SQL化・Task Scheduler設定
- **期待効果**: エンドツーエンド自動実行
- **コスト**: 追加$5/月程度

#### **Phase 14**: 運用最適化・モニタリング強化
- **実装内容**: アラート・異常検知・性能監視
- **技術課題**: 品質劣化の早期発見・通知システム
- **期待効果**: 無人運用レベルの安定性確保

### **二重保存体制**
- **GCS保存**: CSVファイルとして永続保存
- **BigQuery保存**: Looker Studio用データソースとして保存

### **BigQuery prediction_resultsテーブル**
- 予測実行日、対象日時、予測値
- 予測タイプ、モデル情報、作成日時
- 実績値・誤差（後日更新用カラム）

### **データ管理**
- 履歴データの蓄積・分析用
- 予測精度の継続監視
- モデル性能劣化の検出

---

## 💰 コスト・運用考慮事項詳細

### **GCP料金概算（月額）**
| サービス | 用途 | 概算費用 | 備考 |
|---------|------|---------|------|
| Cloud Scheduler | 日次実行トリガー | $0.10 | ジョブ数・実行回数次第 |
| Cloud Functions | データ取得処理 | $2-5 | 実行時間・メモリ使用量次第 |
| BigQuery Storage | データ保存 | $2-3 | データ量・保持期間次第 |
| BigQuery Queries | SQL処理 | $3-5 | クエリ実行量次第 |
| GCS Storage | ファイル保存 | $1-2 | データ量次第 |
| **合計** | **全サービス** | **$8-15** | **実用レベル運用費** |

### **保守・運用作業**
#### **定期作業**
- **モデル再学習**: 月次（性能劣化時）
- **精度監視**: 週次確認（自動アラート併用）
- **データ品質チェック**: 自動化（異常時のみ手動対応）
- **システム更新**: 四半期（API仕様変更・機能追加）

#### **緊急対応**
- **データ取得失敗**: 自動リトライ + 手動確認
- **予測精度劣化**: アラート通知 + 原因調査
- **API制限・障害**: 代替手段 + 復旧待ち
- **GCP障害**: ローカルバックアップ + サービス復旧待ち

### **技術的リスク・対策**
#### **高リスク**
- **Open-Meteo API制限変更**: 代替API検討・複数ソース併用
- **東京電力データ仕様変更**: パーサー修正・フォーマット対応
- **GCP料金変更**: コスト監視・予算アラート設定

#### **中リスク**
- **予測精度の継続的劣化**: 再学習・特徴量見直し
- **BigQueryクエリコスト増大**: クエリ最適化・パーティション設計
- **ローカル実行環境障害**: クラウド移行・冗長化検討

### **自動ダッシュボード更新**
- **データソース**: BigQuery prediction_resultsテーブル
- **更新頻度**: 新データ挿入時に自動更新
- **アクセス設定**: 一般公開URL

### **表示コンテンツ**
- **実績データ**: 過去の電力消費量推移
- **16日間予測**: Open-Meteo API制限対応・高精度予測
- **精度監視**: 予測精度・誤差率の推移（土日祝日対応確認済み）
- **システム情報**: モデル詳細・実行状況

### **ビジネス価値**
- ポートフォリオ・面接でのデモンストレーション
- 技術力の可視的証明
- 実用システムの運用実績

---

## 📅 自動化スケジューリング・実行計画

### **完全自動化時の日次実行タイムライン**
```
08:00 - Cloud Scheduler: データ取得ジョブ実行開始
08:05 - Cloud Functions: 電力・気象データ取得
08:10 - GCS Upload: 生データ永続保存
08:15 - BigQuery: データ投入・特徴量生成SQL実行
08:20 - Scheduled Queries: 予測用データマート更新
08:25 - ローカル Task Scheduler: 予測実行開始
08:35 - 予測完了: 結果CSV生成・品質検証
08:40 - BigQuery Upload: prediction_resultsテーブル更新
08:45 - Looker Studio: 自動データ更新・ダッシュボード反映
08:50 - 完了通知: 実行結果・精度サマリー通知
```

### **エラー発生時の自動復旧フロー**
```
データ取得失敗 → 15分後リトライ → 3回失敗で管理者通知
予測実行失敗 → 前日予測値の延長表示 → 手動確認要求
GCP障害 → ローカル一時保存 → 復旧後一括アップロード
精度劣化検出 → アラート通知 → モデル再学習判断
```

### **日次実行スケジュール**
- **実行時間**: 毎日朝9:00（JST）
- **実行理由**: 東京電力データ更新タイミング考慮
- **実行方法**: Windowsタスクスケジューラ
- **実行時間**: 約10-15分
- **ログ管理**: 日次実行ログの記録・保存

### **障害・エラー対応**
- **データ取得失敗**: 翌日リトライ・欠損日スキップ
- **予測実行失敗**: 前日予測の延長表示
- **GCP障害**: ローカル一時保存・復旧後アップロード
- **品質劣化**: ログ記録・手動確認

---

## 📂 データフロー・ストレージ設計

### **ローカルストレージ**
- **一時データ**: 3日間保持後自動削除
- **モデルファイル**: Phase 9学習済みXGBoostモデル
- **設定ファイル**: GCP認証情報・システム設定
- **ログファイル**: 実行履歴・エラー記録

### **GCSストレージ**
- **生データ**: 日付別ディレクトリでの永続保存
- **予測結果**: CSVファイルでの履歴保存
- **バックアップ**: システム復旧用データ

### **BigQueryストレージ**
- **統合テーブル**: 電力・気象・カレンダーデータ
- **特徴量テーブル**: ML用特徴量データセット
- **予測結果テーブル**: Looker Studio用データソース

---

## 🌤️ Open-Meteo API仕様詳細（Phase 10 WeatherDownloader対応）

### **Historical API（過去データ）**
- **エンドポイント**: `https://archive-api.open-meteo.com/v1/archive`
- **用途**: 昨日分の実績気象データ取得
- **制限**: 最大1年分・時間単位データ
- **レスポンス**: JSON形式・hourlyデータ配列

### **Forecast API（予測データ）**
- **エンドポイント**: `https://api.open-meteo.com/v1/forecast`
- **用途**: 最大16日間の気象予測データ取得
- **精度**: 1-3日目（高解像度1-2km）、4-16日目（グローバル11km）
- **制限**: 最大16日間（`&forecast_days=16`）

### **API制限対応策**
- **レート制限**: 1秒間隔でのリトライ実装
- **エラーハンドリング**: 429エラー時の指数バックオフ
- **基準日分離**: Phase 10運用 vs Phase 5-6再構築での用途分離

---

## 🔄 システム制約・今後の拡張検討

### **現在の制約事項**
- **予測期間**: Open-Meteo APIにより16日間が上限
- **気象データ**: 千葉県1地点のみ（Phase 9結果に基づく）
- **実行環境**: ローカルPC依存（クラウド化は将来検討）

### **拡張可能性**
- **予測期間延長**: 他気象APIとの組み合わせ検討
- **地点拡張**: 関東全域への拡張可能性
- **クラウド化**: GCP Cloud Functions・Cloud Runでの自動化

### **品質保証戦略（Phase 10確立）**
- **精度監視**: 日次でのMAPE・MAE計算
- **異常検知**: 統計的外れ値の自動検出（IQR法）
- **土日祝日対応**: XGBoost欠損値自動処理による安定運用
- **アラート機能**: 精度劣化時の通知システム

---

## 🎯 Phase 11現在の進捗状況・次ステップ

### **完了済み機能（Phase 11準備完了）**
- ✅ **段階的予測システム**: MAPE 3.13%実用レベル達成
- ✅ **CSV出力機能**: 8列構造・Looker Studio連携準備完了
- ✅ **Windows環境対応**: Unicode・仮想環境問題解決済み
- ✅ **環境変数対応**: 他PC実行環境確保・ポータビリティ向上
- ✅ **予測結果データ**: 384時間分・16日間予測データ生成済み

### **Phase 11進行中**
- 🔄 **Looker Studio構築**: データソース接続・ダッシュボード設計
- 🔄 **BigQuery統合**: prediction_resultsテーブル作成・データ投入
- 🔄 **可視化設計**: 時系列・精度・統計グラフの仕様確定

### **Phase 12以降の自動化実装予定**
- ⏳ **Cloud Scheduler**: 段階①データ取得自動化
- ⏳ **BigQuery Scheduled Queries**: 段階②特徴量生成SQL化
- ⏳ **Task Scheduler**: 段階③予測実行自動化
- ⏳ **監視・アラート**: 品質保証・異常検知システム

### **技術的価値・キャリアインパクト**
- **データエンジニア実証**: エンドツーエンドML予測システム構築
- **年収700万円レベル**: 高精度予測・運用品質・自動化設計
- **ポートフォリオ完成度**: GitHub公開・面接デモ・技術説明資料
- **差別化要素**: 実用レベル精度・継続運用・問題解決能力証明

---

## 📝 システム設計書更新履歴

- **2025-09-03**: Phase 11対応・自動化ロードマップ追加・コスト試算・実装状況マトリクス追加
- **Phase 10時点**: WeatherDownloader・土日祝日対応・16日間予測検証完了
- **Phase 9時点**: 特徴量確定・予測精度達成・システムフロー確立