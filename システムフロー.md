# 🎯 エネルギー予測システム フロー設計書

## 📋 システム概要

**目的**: 毎日自動で電力予測を実行し、Looker Studioで公開可能なダッシュボードシステム構築  
**実行環境**: ローカルPC（Windows + VS Code + venv）  
**データ基盤**: GCP（BigQuery + GCS）  
**可視化**: Looker Studio（公開ダッシュボード）  
**予測精度**: MAPE 2.15%（Phase 9達成済み）

---

## 🔄 日次実行フロー概要

### **毎日実行されるパイプライン**
```
① データ取得 → ② GCSアップ → ③ 特徴量生成 → ④ 予測実行 → ⑤ 結果保存 → ⑥ 可視化更新
   (ローカル)     (ローカル)      (ローカル+GCP)     (ローカル)     (ローカル)     (自動)
```

---

## 📊 ① データ取得ステップ

### **電力データ取得**
- **データソース**: 東京電力 TEPCO API
- **取得期間**: 昨日分（24時間分）
- **データ形式**: ZIP形式 → CSV抽出
- **保存先**: ローカル一時ディレクトリ
- **データ項目**: 日付、時刻、実績電力消費量、供給力

### **気象データ取得**
- **データソース**: Open-Meteo API
- **取得地点**: 千葉県（Phase 9で最重要地点として確定）
- **取得期間**: 昨日分（24時間分）
- **保存先**: ローカル一時ディレクトリ
- **データ項目**: 日付、時刻、気温、湿度、降水量、天気コード

### **エラーハンドリング考慮事項**
- **404エラー**: データ未公開時（土日・祝日後）の対応
- **API制限**: レート制限時の待機・リトライ機能
- **通信エラー**: タイムアウト・接続エラー時の復旧処理
- **データ異常**: 欠損値・異常値の検出・品質チェック

---

## 📤 ② GCSアップロードステップ

### **生データの永続保存**
- **電力データ**: GCSバケットの日付別ディレクトリに保存
- **気象データ**: GCSバケットの日付別ディレクトリに保存
- **重複チェック**: 同日データ存在時の上書き処理
- **メタデータ**: アップロード日時・データサイズ・品質情報記録

### **目的**
- 生データのバックアップ・履歴管理
- 将来的なデータ再処理・分析への備え
- システム障害時の復旧用データ確保

---

## 🔧 ③ 特徴量生成ステップ

### **BigQueryでの統合処理**
- **Step 1**: GCSからBigQueryへのデータ投入
- **Step 2**: Phase 5-6で確立した特徴量生成ロジックの実行
- **Step 3**: 予測用データセットの準備・ローカルダウンロード

### **生成される特徴量（Phase 9確定版）**
- **lag_1_business_day**: 1営業日前データ（重要度84.3%）
- **temperature_2m**: 気温（重要度7.2%）
- **時間周期性**: hour_cos, hour_sin
- **カレンダー**: is_weekend, is_holiday, month
- **その他**: 計12特徴量（Phase 9で精度検証済み）

### **データ期間**
- 予測に必要な過去データ（営業日ラグ計算のため約30日分）
- 最新データを含む時系列データセット

---

## 🤖 ④ 予測実行ステップ

### **XGBoost予測エンジン**
- **使用モデル**: Phase 9で学習完了したXGBoostモデル
- **予測精度**: MAPE 2.15%（実証済み）
- **入力データ**: 特徴量生成フェーズで準備されたデータセット

### **予測期間設定**
- **1週間予測**: 今日から7日後まで（168時間分）
- **1ヶ月予測**: 今日から30日後まで（720時間分）

### **予測処理内容**
- Phase 9確立のdropna()戦略適用
- 12特徴量での予測実行
- 予測値・信頼区間・メタデータ生成

### **出力データ形式**
- 予測実行日、予測対象日時、予測値
- 予測タイプ（週間/月間）、モデルバージョン
- 信頼区間、品質指標

---

## 💾 ⑤ 予測結果保存ステップ

### **二重保存体制**
- **GCS保存**: CSVファイルとして永続保存
- **BigQuery保存**: Looker Studio用データソースとして保存

### **BigQuery prediction_resultsテーブル**
- 予測実行日、対象日時、予測値
- 予測タイプ、モデル情報、作成日時
- 実績値・誤差（後日更新用カラム）

### **データ管理**
- 履歴データの蓄積・分析用
- 予測精度の継続監視
- モデル性能劣化の検出

---

## 📊 ⑥ Looker Studio可視化フェーズ

### **自動ダッシュボード更新**
- **データソース**: BigQuery prediction_resultsテーブル
- **更新頻度**: 新データ挿入時に自動更新
- **アクセス設定**: 一般公開URL

### **表示コンテンツ**
- **実績データ**: 過去の電力消費量推移
- **1週間予測**: 近未来の詳細予測
- **1ヶ月予測**: 中期予測・計画用
- **精度監視**: 予測精度・誤差率の推移
- **システム情報**: モデル詳細・実行状況

### **ビジネス価値**
- ポートフォリオ・面接でのデモンストレーション
- 技術力の可視的証明
- 実用システムの運用実績

---

## 🕐 スケジューリング・運用

### **日次実行スケジュール**
- **実行時間**: 毎日朝9:00（JST）
- **実行理由**: 東京電力データ更新タイミング考慮
- **実行方法**: Windowsタスクスケジューラ
- **実行時間**: 約10-15分
- **ログ管理**: 日次実行ログの記録・保存

### **障害・エラー対応**
- **データ取得失敗**: 翌日リトライ・欠損日スキップ
- **予測実行失敗**: 前日予測の延長表示
- **GCP障害**: ローカル一時保存・復旧後アップロード
- **品質劣化**: ログ記録・手動確認

---

## 📂 データフロー・ストレージ設計

### **ローカルストレージ**
- **一時データ**: 3日間保持後自動削除
- **モデルファイル**: Phase 9学習済みXGBoostモデル
- **設定ファイル**: GCP認証情報・システム設定
- **ログファイル**: 実行履歴・エラー記録

### **GCSストレージ**
- **生データ**: 日付別ディレクトリでの永続保存
- **予測結果**: CSVファイルでの履歴保存
- **バックアップ**: システム復旧用データ

### **BigQueryストレージ**
- **統合テーブル**: 電力・気象・カレンダーデータ
- **特徴量テーブル**: ML用特徴量データセット
- **予測結果テーブル**: Looker Studio用データソース
