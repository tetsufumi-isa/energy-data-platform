"""
äºˆæ¸¬å®Ÿè¡Œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« - main_etl.pyã‹ã‚‰å‘¼ã³å‡ºã—ç”¨

æ—¥æ¬¡äºˆæ¸¬å®Ÿè¡Œï¼šä»Šæ—¥ã‹ã‚‰16æ—¥é–“ã®é›»åŠ›ä½¿ç”¨é‡ã‚’äºˆæ¸¬
ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: BigQueryï¼ˆæ˜¨æ—¥ã¾ã§ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ»ä»Šæ—¥ã‹ã‚‰ã®æ°—è±¡ãƒ‡ãƒ¼ã‚¿ï¼‰
å‡ºåŠ›: CSVå½¢å¼ã®äºˆæ¸¬çµæœ + BigQueryã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ­ã‚°
"""

import pandas as pd
import numpy as np
import xgboost as xgb
from datetime import datetime, timedelta
from pathlib import Path
from logging import getLogger
from google.cloud import bigquery
import uuid
import os

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å°‚ç”¨ã®ãƒ­ã‚¬ãƒ¼ã‚’å–å¾—
logger = getLogger('energy_env.prediction_runner')


def run_daily_prediction(project_id="energy-env"):
    """
    æ—¥æ¬¡äºˆæ¸¬å®Ÿè¡Œï¼ˆä»Šæ—¥ã‹ã‚‰16æ—¥é–“ï¼‰

    Args:
        project_id (str): GCPãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID

    Returns:
        dict: å®Ÿè¡Œçµæœã‚µãƒãƒªãƒ¼
    """
    # å®Ÿè¡ŒIDç”Ÿæˆ
    execution_id = str(uuid.uuid4())
    prediction_start_time = datetime.now()

    logger.info(f"æ—¥æ¬¡äºˆæ¸¬å®Ÿè¡Œé–‹å§‹: execution_id={execution_id}")

    try:
        # BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        client = bigquery.Client(project=project_id)

        # ãƒ‡ãƒ¼ã‚¿å–å¾—
        logger.info("BigQueryã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹")
        ml_features_train, future_features, calendar_data = _fetch_data_from_bigquery(client)
        logger.info(f"ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿{len(ml_features_train):,}ä»¶")

        # ç‰¹å¾´é‡å®šç¾©
        features = [
            'hour', 'is_weekend', 'is_holiday', 'month',
            'hour_sin', 'hour_cos',
            'lag_1_day', 'lag_7_day', 'lag_1_business_day',
            'temperature_2m', 'relative_humidity_2m', 'precipitation'
        ]

        # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
        logger.info("XGBoostãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹")
        xgb_model = _train_model(ml_features_train, features)
        logger.info("XGBoostãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†")

        # æ®µéšçš„äºˆæ¸¬å®Ÿè¡Œ
        logger.info("æ®µéšçš„äºˆæ¸¬å®Ÿè¡Œé–‹å§‹")
        predictions = _run_iterative_prediction(
            xgb_model, features, ml_features_train,
            future_features, calendar_data
        )
        logger.info(f"æ®µéšçš„äºˆæ¸¬å®Œäº†: {len(predictions)}ä»¶")

        # CSVä¿å­˜
        logger.info("äºˆæ¸¬çµæœCSVä¿å­˜é–‹å§‹")
        csv_result = _save_predictions_to_csv(predictions, execution_id)
        logger.info(f"CSVä¿å­˜å®Œäº†: {csv_result['csv_file']}")

        # BigQueryä¿å­˜
        logger.info("äºˆæ¸¬çµæœBigQueryä¿å­˜é–‹å§‹")
        bq_result = _save_predictions_to_bigquery(client, predictions, execution_id)

        if bq_result['success']:
            logger.info(f"BigQueryä¿å­˜å®Œäº†: {bq_result['rows_inserted']}è¡Œ")
        else:
            logger.error(f"BigQueryä¿å­˜å¤±æ•—: {bq_result['error']}")

        # å®Ÿè¡Œå®Œäº†
        prediction_end_time = datetime.now()
        duration_seconds = int((prediction_end_time - prediction_start_time).total_seconds())

        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ­ã‚°è¨˜éŒ²
        _save_execution_status(
            client, execution_id, prediction_start_time,
            prediction_end_time, duration_seconds,
            len(predictions), csv_result['success'], bq_result['success']
        )

        logger.info(f"æ—¥æ¬¡äºˆæ¸¬å®Ÿè¡Œå®Œäº†: execution_id={execution_id}")

        return {
            'status': 'success',
            'execution_id': execution_id,
            'prediction_count': len(predictions),
            'csv_file': csv_result['csv_file'],
            'bq_saved': bq_result['success'],
            'duration_seconds': duration_seconds
        }

    except Exception as e:
        logger.error(f"æ—¥æ¬¡äºˆæ¸¬å®Ÿè¡Œå¤±æ•—: {e}")
        return {
            'status': 'failed',
            'error': str(e),
            'execution_id': execution_id
        }


def _fetch_data_from_bigquery(client):
    """BigQueryã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—"""
    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæ˜¨æ—¥ã¾ã§ï¼‰
    yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
    query_ml_features = f"""
    SELECT
        date, hour, actual_power, supply_capacity,
        temperature_2m, relative_humidity_2m, precipitation, weather_code,
        day_of_week, is_weekend, is_holiday, month,
        hour_sin, hour_cos, lag_1_day, lag_7_day, lag_1_business_day
    FROM `energy-env.prod_energy_data.ml_features`
    WHERE date <= '{yesterday}'
    ORDER BY date, hour
    """
    ml_features_train = client.query(query_ml_features).to_dataframe()

    # datetimeåˆ—ä½œæˆ
    ml_features_train['datetime'] = pd.to_datetime(
        ml_features_train['date'].astype(str) + ' ' +
        ml_features_train['hour'].astype(str).str.zfill(2) + ':00:00'
    )
    ml_features_train = ml_features_train.set_index('datetime')

    # äºˆæ¸¬æœŸé–“è¨­å®šï¼ˆä»Šæ—¥ã‹ã‚‰16æ—¥é–“ï¼‰
    today = datetime.now().strftime('%Y-%m-%d')
    end_date_str = (datetime.now() + timedelta(days=15)).strftime('%Y-%m-%d')

    # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒ‡ãƒ¼ã‚¿å–å¾—
    query_calendar = f"""
    SELECT date, day_of_week, is_weekend, is_holiday
    FROM `energy-env.prod_energy_data.calendar_data`
    WHERE date BETWEEN '{today}' AND '{end_date_str}'
    ORDER BY date
    """
    calendar_data = client.query(query_calendar).to_dataframe()
    calendar_data['date'] = pd.to_datetime(calendar_data['date']).dt.date
    calendar_data = calendar_data.set_index('date')

    # äºˆæ¸¬æœŸé–“ã®æ°—è±¡ãƒ»ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒ‡ãƒ¼ã‚¿å–å¾—
    query_future_data = f"""
    SELECT
        w.date, w.hour,
        w.temperature_2m, w.relative_humidity_2m, w.precipitation, w.weather_code,
        c.day_of_week, c.is_weekend, c.is_holiday,
        EXTRACT(MONTH FROM w.date) as month
    FROM (
        SELECT *
        FROM `energy-env.prod_energy_data.weather_data`
        WHERE date BETWEEN '{today}' AND '{end_date_str}'
            AND prefecture = 'chiba'
    ) w
    LEFT JOIN `energy-env.prod_energy_data.calendar_data` c
        ON w.date = c.date
    ORDER BY w.date, w.hour
    """
    future_features = client.query(query_future_data).to_dataframe()
    future_features['datetime'] = pd.to_datetime(
        future_features['date'].astype(str) + ' ' +
        future_features['hour'].astype(str).str.zfill(2) + ':00:00'
    )
    future_features = future_features.set_index('datetime')

    # å¾ªç’°ç‰¹å¾´é‡è¿½åŠ 
    future_features['hour_sin'] = np.sin(2 * np.pi * future_features['hour'] / 24)
    future_features['hour_cos'] = np.cos(2 * np.pi * future_features['hour'] / 24)

    return ml_features_train, future_features, calendar_data


def _train_model(ml_features_train, features):
    """XGBoostãƒ¢ãƒ‡ãƒ«å­¦ç¿’"""
    X_train = ml_features_train[features]
    y_train = ml_features_train['actual_power']

    xgb_model = xgb.XGBRegressor(
        n_estimators=200,
        max_depth=8,
        learning_rate=0.05,
        random_state=42,
        verbosity=0
    )

    xgb_model.fit(X_train, y_train)
    return xgb_model


def _run_iterative_prediction(xgb_model, features, ml_features_train, future_features, calendar_data):
    """æ®µéšçš„äºˆæ¸¬å®Ÿè¡Œ"""
    # å–¶æ¥­æ—¥ãƒ‡ãƒ¼ã‚¿æº–å‚™
    lookback_start = pd.to_datetime(datetime.now() - timedelta(days=20))
    business_days_train = ml_features_train[
        (ml_features_train.index >= lookback_start) &
        (~ml_features_train['is_holiday']) &
        (~ml_features_train['is_weekend'])
    ][['actual_power']]

    business_days_future = calendar_data[
        (~calendar_data['is_holiday']) & (~calendar_data['is_weekend'])
    ].index

    # äºˆæ¸¬æœŸé–“è¨­å®š
    today = datetime.now()
    predictions = {}

    # 16æ—¥é–“ã®æ®µéšçš„äºˆæ¸¬
    for day in range(16):
        current_date = today + timedelta(days=day)

        for hour in range(24):
            target_datetime = current_date.replace(hour=hour, minute=0, second=0, microsecond=0)

            # ç‰¹å¾´é‡æº–å‚™
            feature_values = _prepare_features(
                target_datetime, predictions, features,
                future_features, ml_features_train,
                business_days_train, business_days_future
            )

            # äºˆæ¸¬å®Ÿè¡Œ
            X_pred = pd.DataFrame([feature_values], columns=features)
            pred_value = xgb_model.predict(X_pred)[0]
            predictions[target_datetime] = pred_value

    return predictions


def _prepare_features(target_datetime, predictions, features, future_features,
                      ml_features_train, business_days_train, business_days_future):
    """äºˆæ¸¬å¯¾è±¡æ™‚åˆ»ã®ç‰¹å¾´é‡ã‚’æº–å‚™"""
    if target_datetime not in future_features.index:
        raise ValueError(f"äºˆæ¸¬å¯¾è±¡æ—¥æ™‚ {target_datetime} ãŒ future_features ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    row = future_features.loc[target_datetime]
    feature_values = []

    for feature in features:
        if feature == 'lag_1_day':
            lag_datetime = target_datetime - timedelta(days=1)
            if lag_datetime in predictions:
                feature_values.append(predictions[lag_datetime])
            elif lag_datetime in ml_features_train.index:
                feature_values.append(ml_features_train.loc[lag_datetime, 'actual_power'])
            else:
                feature_values.append(np.nan)

        elif feature == 'lag_7_day':
            lag_datetime = target_datetime - timedelta(days=7)
            if lag_datetime in predictions:
                feature_values.append(predictions[lag_datetime])
            elif lag_datetime in ml_features_train.index:
                feature_values.append(ml_features_train.loc[lag_datetime, 'actual_power'])
            else:
                feature_values.append(np.nan)

        elif feature == 'lag_1_business_day':
            found = False
            for days_back in range(1, 21):
                lag_datetime = target_datetime - timedelta(days=days_back)
                lag_date = lag_datetime.date()

                if lag_datetime in predictions and lag_date in business_days_future:
                    feature_values.append(predictions[lag_datetime])
                    found = True
                    break
                elif lag_datetime in business_days_train.index:
                    feature_values.append(business_days_train.loc[lag_datetime, 'actual_power'])
                    found = True
                    break

            if not found:
                feature_values.append(np.nan)
        else:
            feature_values.append(row[feature])

    return feature_values


def _save_predictions_to_csv(predictions, execution_id):
    """äºˆæ¸¬çµæœã‚’CSVä¿å­˜"""
    energy_env_path = os.getenv('ENERGY_ENV_PATH', '.')
    base_path = Path(energy_env_path) / 'data' / 'predictions'
    base_path.mkdir(parents=True, exist_ok=True)

    now = datetime.now()
    timestamp = now.strftime('%Y%m%d_%H%M%S')

    prediction_data = []
    for target_datetime, predicted_value in predictions.items():
        prediction_data.append({
            'execution_id': execution_id,
            'prediction_date': target_datetime.strftime('%Y-%m-%d'),
            'prediction_hour': target_datetime.hour,
            'predicted_power_kwh': round(predicted_value, 2),
            'created_at': now.strftime('%Y-%m-%d %H:%M:%S')
        })

    predictions_df = pd.DataFrame(prediction_data)
    csv_filename = f"predictions_{timestamp}.csv"
    csv_filepath = base_path / csv_filename
    predictions_df.to_csv(csv_filepath, index=False, encoding='utf-8')

    return {
        'success': True,
        'csv_file': str(csv_filepath),
        'timestamp': timestamp
    }


def _save_predictions_to_bigquery(client, predictions, execution_id):
    """äºˆæ¸¬çµæœã‚’BigQueryä¿å­˜"""
    try:
        table_ref = f"{client.project}.prod_energy_data.prediction_results"

        bq_prediction_data = []
        for target_datetime, predicted_value in predictions.items():
            bq_prediction_data.append({
                'execution_id': execution_id,
                'prediction_date': target_datetime.strftime('%Y-%m-%d'),
                'prediction_hour': target_datetime.hour,
                'predicted_power_kwh': round(predicted_value, 2),
                'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            })

        bq_predictions_df = pd.DataFrame(bq_prediction_data)

        job = client.load_table_from_dataframe(
            bq_predictions_df,
            table_ref,
            job_config=bigquery.LoadJobConfig(write_disposition="WRITE_APPEND")
        )
        job.result()

        return {
            'success': True,
            'rows_inserted': len(bq_predictions_df)
        }

    except Exception as e:
        return {
            'success': False,
            'error': str(e),
            'rows_inserted': 0
        }


def _save_execution_status(client, execution_id, start_time, end_time,
                           duration_seconds, prediction_count, csv_saved, bq_saved):
    """å®Ÿè¡Œã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’BigQueryã«è¨˜éŒ²"""
    try:
        table_id = 'energy-env.prod_energy_data.process_execution_log'

        process_status = {
            'execution_id': execution_id,
            'date': datetime.now().strftime('%Y-%m-%d'),
            'process_type': 'ML_PREDICTION',
            'status': 'SUCCESS',
            'error_message': None,
            'started_at': start_time.isoformat(),
            'completed_at': end_time.isoformat(),
            'duration_seconds': duration_seconds,
            'records_processed': prediction_count,
            'file_size_mb': None,
            'additional_info': f"csv_saved={csv_saved}, bq_saved={bq_saved}"
        }

        errors = client.insert_rows_json(table_id, [process_status])

        if errors:
            logger.error(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ­ã‚°BQä¿å­˜ã‚¨ãƒ©ãƒ¼: {errors}")
        else:
            logger.info(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ­ã‚°BQä¿å­˜æˆåŠŸ: execution_id={execution_id}")

    except Exception as e:
        logger.error(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ­ã‚°ä¿å­˜å¤±æ•—: {e}")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•° - æ—¥æ¬¡äºˆæ¸¬å®Ÿè¡Œ"""
    import sys

    print("ğŸš€ æ—¥æ¬¡äºˆæ¸¬å®Ÿè¡Œé–‹å§‹ï¼ˆä»Šæ—¥ã‹ã‚‰16æ—¥é–“ï¼‰")

    try:
        result = run_daily_prediction()

        if result['status'] == 'success':
            print(f"âœ… äºˆæ¸¬å®Ÿè¡ŒæˆåŠŸ: {result['prediction_count']}ä»¶")
            print(f"ğŸ“ CSVä¿å­˜: {result['csv_file']}")
            print(f"ğŸ’¾ BigQueryä¿å­˜: {'æˆåŠŸ' if result['bq_saved'] else 'å¤±æ•—'}")
            print("ğŸ äºˆæ¸¬å®Ÿè¡Œå®Œäº†")
        else:
            print(f"âŒ äºˆæ¸¬å®Ÿè¡Œå¤±æ•—: {result.get('error', 'Unknown error')}")
            sys.exit(1)

    except Exception as e:
        print(f"ğŸ’¥ äºˆæ¸¬å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
