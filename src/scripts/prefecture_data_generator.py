"""
éƒ½çœŒåˆ¥é›»åŠ›Ã—æ°—è±¡ãƒ‡ãƒ¼ã‚¿è‡ªå‹•ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆèª¿æŸ»ç”¨ãƒ»æ›¸ãæ¨ã¦ï¼‰

ç”¨é€”: æ°—æ¸©Ã—ç¥æ—¥Ã—éƒ½çœŒåˆ¥åˆ†æã®ãŸã‚ã®ä¸€æ™‚çš„ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
å®Ÿè¡Œ: python src/scripts/prefecture_data_generator.py

æ³¨æ„: æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æç”¨ã®ä½¿ã„æ¨ã¦ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã™
"""

import os
import pandas as pd
from google.cloud import bigquery
from pathlib import Path
from logging import getLogger

# ãƒ­ã‚°è¨­å®š
logger = getLogger(__name__)

class PrefectureDataGenerator:
    """éƒ½çœŒåˆ¥ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, project_id="energy-env"):
        """åˆæœŸåŒ–"""
        self.project_id = project_id
        self.client = bigquery.Client(project=project_id)
        # çµ¶å¯¾ãƒ‘ã‚¹æŒ‡å®š
        self.output_dir = Path(r"C:/Users/tetsu/dev/energy-env/data/exploration")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # é–¢æ±9éƒ½çœŒ
        self.prefectures = [
            'tokyo', 'kanagawa', 'saitama', 'chiba',
            'ibaraki', 'tochigi', 'gunma', 'yamanashi', 'shizuoka'
        ]
        
        logger.info(f"Prefecture data generator initialized for {len(self.prefectures)} prefectures")
    
    def create_prefecture_query(self, prefecture):
        """éƒ½çœŒåˆ¥çµ±åˆã‚¯ã‚¨ãƒªç”Ÿæˆ"""
        query = f"""
        SELECT 
            -- é›»åŠ›ãƒ‡ãƒ¼ã‚¿
            energy.date,
            energy.hour,
            energy.actual_power,
            energy.supply_capacity,
            
            -- æ°—è±¡ãƒ‡ãƒ¼ã‚¿
            weather.prefecture,
            weather.temperature_2m,
            weather.relative_humidity_2m,
            weather.precipitation,
            weather.weather_code,
            
            -- ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒ‡ãƒ¼ã‚¿
            calendar.day_of_week,
            calendar.is_weekend,
            calendar.is_holiday,
            
            -- æ´¾ç”Ÿé …ç›®
            EXTRACT(MONTH FROM energy.date) as month
            
        FROM `{self.project_id}.dev_energy_data.energy_data_hourly` energy
        LEFT JOIN `{self.project_id}.dev_energy_data.weather_data` weather 
            ON energy.date = weather.date 
            AND energy.hour = CAST(weather.hour AS INTEGER)
            AND weather.prefecture = '{prefecture}'
        LEFT JOIN `{self.project_id}.dev_energy_data.calendar_data` calendar
            ON energy.date = calendar.date
        WHERE weather.prefecture IS NOT NULL
        ORDER BY energy.date, energy.hour
        """
        return query
    
    def generate_prefecture_data(self, prefecture):
        """éƒ½çœŒåˆ¥ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ»ä¿å­˜"""
        try:
            logger.info(f"Generating data for {prefecture}...")
            
            # ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
            query = self.create_prefecture_query(prefecture)
            df = self.client.query(query).to_dataframe()
            
            # ãƒ‡ãƒ¼ã‚¿ç¢ºèª
            logger.info(f"{prefecture}: {len(df)} records retrieved")
            if len(df) == 0:
                logger.warning(f"No data found for {prefecture}")
                return None
            
            # CSVä¿å­˜
            csv_filename = f"{prefecture}_power_weather.csv"
            csv_path = self.output_dir / csv_filename
            df.to_csv(csv_path, index=False, encoding='utf-8')
            
            logger.info(f"{prefecture}: Saved to {csv_path}")
            return csv_path
            
        except Exception as e:
            logger.error(f"Error generating data for {prefecture}: {e}")
            return None
    
    def generate_all_prefectures(self):
        """å…¨éƒ½çœŒãƒ‡ãƒ¼ã‚¿è‡ªå‹•ç”Ÿæˆ"""
        results = {'success': [], 'failed': []}
        
        print(f"ğŸš€ Starting data generation for {len(self.prefectures)} prefectures...")
        
        for i, prefecture in enumerate(self.prefectures, 1):
            print(f"ğŸ“Š Processing {prefecture} ({i}/{len(self.prefectures)})...")
            
            csv_path = self.generate_prefecture_data(prefecture)
            
            if csv_path:
                results['success'].append({
                    'prefecture': prefecture,
                    'csv_path': str(csv_path)
                })
                print(f"âœ… {prefecture}: Success")
            else:
                results['failed'].append(prefecture)
                print(f"âŒ {prefecture}: Failed")
        
        return results
    



def print_results(results):
    """çµæœè¡¨ç¤º"""
    success_count = len(results['success'])
    failed_count = len(results['failed'])
    
    print(f"\n{'='*60}")
    print("ğŸ“Š éƒ½çœŒåˆ¥ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆçµæœ")
    print('='*60)
    
    if results['success']:
        print(f"\nâœ… æˆåŠŸ: {success_count}éƒ½çœŒ")
        for item in results['success']:
            print(f"  {item['prefecture']}: {Path(item['csv_path']).name}")
    
    if results['failed']:
        print(f"\nâŒ å¤±æ•—: {failed_count}éƒ½çœŒ")
        for prefecture in results['failed']:
            print(f"  {prefecture}")
    
    print(f"\nğŸ“ˆ ç·åˆçµæœ: æˆåŠŸ{success_count}ä»¶ / å¤±æ•—{failed_count}ä»¶")
    print(f"ğŸ“‚ ä¿å­˜å…ˆ: C:/Users/tetsu/dev/energy-env/data/exploration/")
    print('='*60)


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    # ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå™¨åˆæœŸåŒ–
    generator = PrefectureDataGenerator()
    
    # å…¨éƒ½çœŒãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Ÿè¡Œ
    results = generator.generate_all_prefectures()
    
    # çµæœè¡¨ç¤º
    print_results(results)
    
    # æˆåŠŸã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§è¡¨ç¤º
    if results['success']:
        print("\nğŸ“‹ ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
        for item in results['success']:
            csv_path = Path(item['csv_path'])
            file_size = csv_path.stat().st_size / 1024 / 1024  # MB
            print(f"  {csv_path.name}: {file_size:.1f}MB")


if __name__ == "__main__":
    main()