# %%
# ================================================================
# æ®µéšçš„äºˆæ¸¬ãƒ†ã‚¹ãƒˆå®Ÿè£…ï¼ˆä¿®æ­£ç‰ˆãƒ»dropna()ãªã—ï¼‰
# ç›®çš„: å®Ÿé‹ç”¨ã§ã®äºˆæ¸¬å€¤ä¾å­˜ã«ã‚ˆã‚‹ç²¾åº¦åŠ£åŒ–æ¸¬å®š
# æœŸé–“: 2025-06-01 ï½ 2025-06-16 (16æ—¥é–“Ã—24æ™‚é–“=384å›äºˆæ¸¬)
# ä¿®æ­£ç‚¹: dropna()å‰Šé™¤ãƒ»Phase 10åœŸæ—¥ç¥æ—¥å¯¾å¿œã¨åŒã˜æ¡ä»¶
# ================================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, r2_score
import xgboost as xgb
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = 'Meiryo'
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10

print("ğŸ”„ æ®µéšçš„äºˆæ¸¬ãƒ†ã‚¹ãƒˆé–‹å§‹ï¼ˆä¿®æ­£ç‰ˆãƒ»dropna()ãªã—ï¼‰")
print("=" * 60)

# %%
# ================================================================
# 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ»åŸºæœ¬ç¢ºèª
# ================================================================

# ml_features.csvã®èª­ã¿è¾¼ã¿
ml_features = pd.read_csv('../../../data/ml/ml_features.csv')
print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†")
print(f"ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {ml_features.shape}")

# dateã¨houråˆ—ã‹ã‚‰datetimeåˆ—ã‚’ä½œæˆ
ml_features['datetime'] = pd.to_datetime(ml_features['date'].astype(str) + ' ' + ml_features['hour'].astype(str).str.zfill(2) + ':00:00')

# åˆ—åç¢ºèª
print(f"åˆ—å: {list(ml_features.columns)}")

# datetimeåˆ—ã®ç¢ºèªï¼ˆè¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³å¯¾å¿œï¼‰
datetime_columns = [col for col in ml_features.columns if 'date' in col.lower()]
print(f"æ—¥æ™‚é–¢é€£åˆ—: {datetime_columns}")

# æœ€åˆã®æ•°è¡Œç¢ºèª
print(f"\næœ€åˆã®5è¡Œ:")
print(ml_features.head())

# calendar_data_with_prev_business.csvèª­ã¿è¾¼ã¿
calendar_data = pd.read_csv('../../../data/ml/calendar_data_with_prev_business.csv')
print(f"ğŸ“… å–¶æ¥­æ—¥ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼èª­ã¿è¾¼ã¿å®Œäº†")
print(f"ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {calendar_data.shape}")

# calendar_dataã®dateåˆ—ã‚’pandas datetimeã«å¤‰æ›
calendar_data['date'] = pd.to_datetime(calendar_data['date'])

# datetimeåˆ—ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«è¨­å®šï¼ˆé«˜é€Ÿæ¤œç´¢ã®ãŸã‚ï¼‰
ml_features = ml_features.set_index('datetime')
calendar_data = calendar_data.set_index('date')

print(f"âœ… ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†")

# %%
# ================================================================
# 2. Phase 9ç‰¹å¾´é‡å®šç¾©ï¼ˆ12ç‰¹å¾´é‡ï¼‰
# ================================================================

# Phase 9ã§ä½¿ç”¨ã—ãŸ12ç‰¹å¾´é‡ã‚’å®šç¾©
features = [
    'hour',                    # æ™‚é–“ï¼ˆ0-23ï¼‰
    'is_weekend',             # é€±æœ«ãƒ•ãƒ©ã‚°
    'is_holiday',             # ç¥æ—¥ãƒ•ãƒ©ã‚°  
    'month',                  # æœˆï¼ˆ1-12ï¼‰
    'hour_sin',               # æ™‚é–“å‘¨æœŸæ€§ï¼ˆsinï¼‰
    'hour_cos',               # æ™‚é–“å‘¨æœŸæ€§ï¼ˆcosï¼‰
    'lag_1_day',              # 1æ—¥å‰åŒæ™‚åˆ»ï¼ˆé‡è¦ï¼ï¼‰
    'lag_7_day',              # 7æ—¥å‰åŒæ™‚åˆ»
    'lag_1_business_day',     # 1å–¶æ¥­æ—¥å‰åŒæ™‚åˆ»ï¼ˆé‡è¦åº¦84.3%ï¼ï¼‰
    'temperature_2m',         # æ°—æ¸©
    'relative_humidity_2m',   # æ¹¿åº¦
    'precipitation'           # é™æ°´é‡
]

print(f"\nğŸ”§ ä½¿ç”¨ç‰¹å¾´é‡: {len(features)}å€‹")
for i, feature in enumerate(features, 1):
    print(f"  {i:2d}. {feature}")

# %%
# ================================================================
# 3. Phase 9ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆ2025-05-31ã¾ã§ãƒ»dropna()ãªã—ï¼‰
# ================================================================

# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆ2025-05-31ã¾ã§ï¼‰
train_end_date = '2025-05-31 23:00:00'
train_data = ml_features[ml_features.index <= train_end_date].copy()

print(f"\nğŸ“š ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆdropna()ãªã—ç‰ˆï¼‰")
print(f"å­¦ç¿’æœŸé–“: {train_data.index.min()} ï½ {train_data.index.max()}")
print(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(train_data):,}ä»¶")

# ã€ä¿®æ­£ã€‘dropna()ã‚’å‰Šé™¤ - XGBoostæ¬ æå€¤è‡ªå‹•å‡¦ç†ã‚’æ´»ç”¨
print(f"âœ… dropna()ãªã— - XGBoostæ¬ æå€¤è‡ªå‹•å‡¦ç†ä½¿ç”¨")
print(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆæ¬ æå€¤è¾¼ã¿ï¼‰: {len(train_data):,}ä»¶")

# æ¬ æå€¤çŠ¶æ³ç¢ºèª
missing_info = train_data[features].isnull().sum()
print(f"\nğŸ“Š å„ç‰¹å¾´é‡ã®æ¬ æå€¤çŠ¶æ³:")
for feature in features:
    missing_count = missing_info[feature]
    missing_rate = missing_count / len(train_data) * 100
    print(f"  {feature:20s}: {missing_count:5d}ä»¶ ({missing_rate:5.1f}%)")

# ç‰¹å¾´é‡ãƒ»ç›®çš„å¤‰æ•°åˆ†é›¢ï¼ˆdropna()ãªã—ï¼‰
X_train = train_data[features]  # æ¬ æå€¤è¾¼ã¿ã§å­¦ç¿’
y_train = train_data['actual_power']

# Phase 9ã¨åŒã˜XGBoostãƒ¢ãƒ‡ãƒ«å­¦ç¿’
xgb_model = xgb.XGBRegressor(
    n_estimators=200,
    max_depth=8,
    learning_rate=0.05,
    random_state=42,
    verbosity=0
)

print(f"\nğŸ¤– XGBoostãƒ¢ãƒ‡ãƒ«å­¦ç¿’ä¸­ï¼ˆæ¬ æå€¤è‡ªå‹•å‡¦ç†ï¼‰...")
xgb_model.fit(X_train, y_train)
print(f"âœ… ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†")

# %%
# ================================================================
# 4. å–¶æ¥­æ—¥ãƒãƒƒãƒ”ãƒ³ã‚°é–¢æ•°ã®æº–å‚™
# ================================================================

def get_prev_business_day(target_date):
    """æŒ‡å®šæ—¥ã®å‰å–¶æ¥­æ—¥ã‚’å–å¾—"""
    target_date_str = target_date.strftime('%Y-%m-%d')
    
    if target_date_str in calendar_data.index:
        prev_business_str = calendar_data.loc[target_date_str, 'prev_business_day']
        if pd.notna(prev_business_str):
            return pd.to_datetime(prev_business_str).date()
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å˜ç´”ã«å‰æ—¥ã‚’è¿”ã™
    return (target_date - timedelta(days=1)).date()

def prepare_features_for_prediction_debug(target_datetime, predictions_dict):
    """äºˆæ¸¬å¯¾è±¡æ™‚åˆ»ã®ç‰¹å¾´é‡ã‚’æº–å‚™ï¼ˆãƒ‡ãƒãƒƒã‚°ç‰ˆï¼‰"""
    print(f"\n{'='*60}")
    print(f"ğŸ” ç‰¹å¾´é‡ãƒ‡ãƒãƒƒã‚°: {target_datetime}")
    print(f"{'='*60}")
    
    # åŸºæœ¬ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç‰¹å¾´é‡ï¼ˆç¢ºå®šå€¤ï¼‰
    hour = target_datetime.hour
    is_weekend = 1 if target_datetime.weekday() >= 5 else 0
    month = target_datetime.month
    hour_sin = np.sin(2 * np.pi * hour / 24)
    hour_cos = np.cos(2 * np.pi * hour / 24)
    
    print(f"ğŸ“… åŸºæœ¬ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç‰¹å¾´é‡:")
    print(f"  hour: {hour}")
    print(f"  is_weekend: {is_weekend} ({'é€±æœ«' if is_weekend else 'å¹³æ—¥'})")
    print(f"  month: {month}")
    print(f"  hour_sin: {hour_sin:.4f}")
    print(f"  hour_cos: {hour_cos:.4f}")
    
    # ç¥æ—¥ãƒ•ãƒ©ã‚°ï¼ˆæ­£ç¢ºãªå®Ÿè£…ï¼‰
    target_date_str = target_datetime.strftime('%Y-%m-%d')
    if target_date_str in calendar_data.index:
        is_holiday = 1 if calendar_data.loc[target_date_str, 'is_holiday'] else 0
        print(f"  is_holiday: {is_holiday} (ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å–å¾—)")
    else:
        is_holiday = 0  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        print(f"  is_holiday: {is_holiday} (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤)")
    
    # æ°—è±¡ãƒ‡ãƒ¼ã‚¿ï¼ˆml_featuresã®å®Ÿç¸¾å€¤ä½¿ç”¨ï¼‰
    print(f"\nğŸŒ¤ï¸ æ°—è±¡ç‰¹å¾´é‡:")
    if target_datetime in ml_features.index:
        temperature_2m = ml_features.loc[target_datetime, 'temperature_2m']
        relative_humidity_2m = ml_features.loc[target_datetime, 'relative_humidity_2m']
        precipitation = ml_features.loc[target_datetime, 'precipitation']
        print(f"  temperature_2m: {temperature_2m}Â°C (å®Ÿç¸¾å€¤)")
        print(f"  relative_humidity_2m: {relative_humidity_2m}% (å®Ÿç¸¾å€¤)")
        print(f"  precipitation: {precipitation}mm (å®Ÿç¸¾å€¤)")
    else:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤
        temperature_2m = 20.0
        relative_humidity_2m = 60.0
        precipitation = 0.0
        print(f"  temperature_2m: {temperature_2m}Â°C (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)")
        print(f"  relative_humidity_2m: {relative_humidity_2m}% (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)")
        print(f"  precipitation: {precipitation}mm (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)")

    # lag_1_dayï¼ˆå‰æ—¥åŒæ™‚åˆ»ï¼‰
    print(f"\nâ° ãƒ©ã‚°ç‰¹å¾´é‡:")
    lag_1_day_datetime = target_datetime - timedelta(days=1)
    print(f"  lag_1_dayå‚ç…§æ™‚åˆ»: {lag_1_day_datetime}")

    if lag_1_day_datetime in ml_features.index and lag_1_day_datetime <= pd.to_datetime('2025-05-31 23:00:00'):
        lag_1_day = ml_features.loc[lag_1_day_datetime, 'actual_power']
        print(f"  lag_1_day: {lag_1_day}ä¸‡kW (å®Ÿç¸¾å€¤)")
    elif lag_1_day_datetime in predictions_dict:
        lag_1_day = predictions_dict[lag_1_day_datetime]  # äºˆæ¸¬å€¤ä½¿ç”¨
        print(f"  lag_1_day: {lag_1_day}ä¸‡kW (äºˆæ¸¬å€¤)")
    else:
        lag_1_day = 3500.0  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤
        print(f"  lag_1_day: {lag_1_day}ä¸‡kW (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)")

    # lag_7_dayï¼ˆ7æ—¥å‰åŒæ™‚åˆ»ï¼‰
    lag_7_day_datetime = target_datetime - timedelta(days=7)
    print(f"  lag_7_dayå‚ç…§æ™‚åˆ»: {lag_7_day_datetime}")

    if lag_7_day_datetime in ml_features.index:
        lag_7_day = ml_features.loc[lag_7_day_datetime, 'actual_power']
        print(f"  lag_7_day: {lag_7_day}ä¸‡kW (å®Ÿç¸¾å€¤)")
    elif lag_7_day_datetime in predictions_dict:
        lag_7_day = predictions_dict[lag_7_day_datetime]  # 6/8ä»¥é™ã§äºˆæ¸¬å€¤ä½¿ç”¨
        print(f"  lag_7_day: {lag_7_day}ä¸‡kW (äºˆæ¸¬å€¤)")
    else:
        lag_7_day = 3500.0  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤
        print(f"  lag_7_day: {lag_7_day}ä¸‡kW (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)")

    # lag_1_business_dayï¼ˆå‰å–¶æ¥­æ—¥åŒæ™‚åˆ»ï¼‰- æœ€é‡è¦ç‰¹å¾´é‡ï¼
    prev_business_date = get_prev_business_day(target_datetime)
    lag_1_business_day_datetime = pd.to_datetime(f"{prev_business_date} {target_datetime.time()}")
    print(f"  lag_1_business_dayå‚ç…§æ™‚åˆ»: {lag_1_business_day_datetime}")

    if lag_1_business_day_datetime in ml_features.index and lag_1_business_day_datetime <= pd.to_datetime('2025-05-31 23:00:00'):
        lag_1_business_day = ml_features.loc[lag_1_business_day_datetime, 'actual_power']
        print(f"  lag_1_business_day: {lag_1_business_day}ä¸‡kW (å®Ÿç¸¾å€¤)")
    elif lag_1_business_day_datetime in predictions_dict:
        lag_1_business_day = predictions_dict[lag_1_business_day_datetime]  # äºˆæ¸¬å€¤ä½¿ç”¨
        print(f"  lag_1_business_day: {lag_1_business_day}ä¸‡kW (äºˆæ¸¬å€¤)")
    else:
        lag_1_business_day = 3500.0  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤  
        print(f"  lag_1_business_day: {lag_1_business_day}ä¸‡kW (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)")

    # ç‰¹å¾´é‡è¾æ›¸ä½œæˆ
    feature_values = [
        hour,                    # hour
        is_weekend,             # is_weekend  
        is_holiday,             # is_holiday
        month,                  # month
        hour_sin,               # hour_sin
        hour_cos,               # hour_cos
        lag_1_day,              # lag_1_dayï¼ˆå®Ÿç¸¾å€¤â†’äºˆæ¸¬å€¤ã«æ®µéšç§»è¡Œï¼‰
        lag_7_day,              # lag_7_dayï¼ˆ6/8ä»¥é™ã§äºˆæ¸¬å€¤ä½¿ç”¨ï¼‰
        lag_1_business_day,     # lag_1_business_dayï¼ˆå®Ÿç¸¾å€¤â†’äºˆæ¸¬å€¤ã«æ®µéšç§»è¡Œï¼‰
        temperature_2m,         # temperature_2m
        relative_humidity_2m,   # relative_humidity_2m
        precipitation           # precipitation
    ]
    
    print(f"\nğŸ“‹ ç‰¹å¾´é‡æœ€çµ‚ç¢ºèª:")
    for i, (feat_name, feat_val) in enumerate(zip(features, feature_values)):
        print(f"  {i+1:2d}. {feat_name:20s}: {feat_val}")
    
    return feature_values

# %%
# ================================================================
# 5. æ®µéšçš„äºˆæ¸¬å®Ÿè¡Œï¼ˆ2025-06-01 ï½ 2025-06-16ï¼‰
# ================================================================

# äºˆæ¸¬æœŸé–“è¨­å®š
start_date = pd.to_datetime('2025-06-01')
end_date = pd.to_datetime('2025-06-16')

# äºˆæ¸¬çµæœæ ¼ç´è¾æ›¸
predictions = {}
daily_results = []

print(f"\nğŸ”„ æ®µéšçš„äºˆæ¸¬å®Ÿè¡Œé–‹å§‹")
print(f"äºˆæ¸¬æœŸé–“: {start_date.date()} ï½ {end_date.date()}")
print(f"äºˆæ¸¬å›æ•°: {16 * 24}å›ï¼ˆ16æ—¥Ã—24æ™‚é–“ï¼‰")
print(f"âœ… dropna()ãªã— - XGBoostæ¬ æå€¤è‡ªå‹•å‡¦ç†ä½¿ç”¨")

# 16æ—¥é–“ã®æ®µéšçš„äºˆæ¸¬
current_date = start_date

for day in range(16):
    daily_predictions = []
    daily_actuals = []
    
    print(f"\nğŸ“… Day {day+1}: {current_date.strftime('%Y-%m-%d')}")
    
    # 1æ—¥24æ™‚é–“ã®äºˆæ¸¬
    for hour in range(24):
        target_datetime = current_date + timedelta(hours=hour)
        
        # ç‰¹å¾´é‡æº–å‚™
        feature_values = prepare_features_for_prediction_debug(target_datetime, predictions)
        
        # DataFrameã«å¤‰æ›ï¼ˆXGBoostã«å…¥åŠ›ï¼‰
        X_pred = pd.DataFrame([feature_values], columns=features)
        
        # äºˆæ¸¬å®Ÿè¡Œ
        pred_value = xgb_model.predict(X_pred)[0]
        predictions[target_datetime] = pred_value
        daily_predictions.append(pred_value)
        
        # å®Ÿç¸¾å€¤å–å¾—ï¼ˆæ¤œè¨¼ç”¨ï¼‰
        if target_datetime in ml_features.index:
            actual_value = ml_features.loc[target_datetime, 'actual_power']
            daily_actuals.append(actual_value)
    
    # æ—¥åˆ¥ç²¾åº¦è¨ˆç®—
    if len(daily_actuals) == 24:  # å®Œå…¨ãª1æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆ
        daily_mape = mean_absolute_percentage_error(daily_actuals, daily_predictions) * 100
        daily_mae = mean_absolute_error(daily_actuals, daily_predictions)
        daily_r2 = r2_score(daily_actuals, daily_predictions)
        
        daily_results.append({
            'day': day + 1,
            'date': current_date.strftime('%Y-%m-%d'),
            'mape': daily_mape,
            'mae': daily_mae,
            'r2': daily_r2,
            'predictions_mean': np.mean(daily_predictions),
            'actuals_mean': np.mean(daily_actuals)
        })
        
        print(f"  MAPE: {daily_mape:.2f}%, MAE: {daily_mae:.1f}ä¸‡kW, RÂ²: {daily_r2:.4f}")
    
    current_date += timedelta(days=1)

print(f"\nâœ… æ®µéšçš„äºˆæ¸¬å®Œäº†")

# %%
# ================================================================
# 6. å…¨æœŸé–“ç²¾åº¦è¨ˆç®—ãƒ»çµæœåˆ†æ
# ================================================================

# å…¨æœŸé–“ã®äºˆæ¸¬å€¤ãƒ»å®Ÿç¸¾å€¤åé›†
all_predictions = []
all_actuals = []
prediction_datetimes = []

for dt, pred in predictions.items():
    if dt in ml_features.index:
        all_predictions.append(pred)
        all_actuals.append(ml_features.loc[dt, 'actual_power'])
        prediction_datetimes.append(dt)

# å…¨æœŸé–“ç²¾åº¦è¨ˆç®—
overall_mape = mean_absolute_percentage_error(all_actuals, all_predictions) * 100
overall_mae = mean_absolute_error(all_actuals, all_predictions)
overall_r2 = r2_score(all_actuals, all_predictions)

print(f"\nğŸ“Š æ®µéšçš„äºˆæ¸¬ å…¨æœŸé–“çµæœ")
print(f"=" * 40)
print(f"äºˆæ¸¬ä»¶æ•°: {len(all_predictions)}ä»¶")
print(f"MAPE: {overall_mape:.2f}%")
print(f"MAE:  {overall_mae:.2f}ä¸‡kW")
print(f"RÂ²:   {overall_r2:.4f}")

# å‰å›å›ºå®šäºˆæ¸¬çµæœã¨ã®æ¯”è¼ƒ
print(f"\nğŸ“ˆ å‰å›å›ºå®šäºˆæ¸¬çµæœã¨ã®æ¯”è¼ƒ")
print(f"=" * 40)
print(f"å‰å›å›ºå®šäºˆæ¸¬ï¼ˆMAPEï¼‰: 2.54%ï¼ˆPhase 10åœŸæ—¥ç¥æ—¥å¯¾å¿œï¼‰")
print(f"ä»Šå›æ®µéšçš„äºˆæ¸¬ï¼ˆMAPEï¼‰: {overall_mape:.2f}%")

if overall_mape <= 2.54:
    print(f"âœ… æ®µéšçš„äºˆæ¸¬ã§ã‚‚é«˜ç²¾åº¦ã‚’ç¶­æŒ")
elif overall_mape <= 3.5:
    print(f"âš ï¸ æ®µéšçš„äºˆæ¸¬ã§è»½åº¦ã®ç²¾åº¦åŠ£åŒ–ï¼ˆå®Ÿç”¨ãƒ¬ãƒ™ãƒ«å†…ï¼‰")
    degradation_rate = (overall_mape - 2.54) / 2.54 * 100
    print(f"   ç²¾åº¦åŠ£åŒ–ç‡: {degradation_rate:.1f}%")
elif overall_mape <= 5.0:
    print(f"âš ï¸ æ®µéšçš„äºˆæ¸¬ã§ä¸­ç¨‹åº¦ã®ç²¾åº¦åŠ£åŒ–ï¼ˆè¦æ³¨æ„ãƒ¬ãƒ™ãƒ«ï¼‰")
    degradation_rate = (overall_mape - 2.54) / 2.54 * 100
    print(f"   ç²¾åº¦åŠ£åŒ–ç‡: {degradation_rate:.1f}%")
else:
    print(f"âŒ æ®µéšçš„äºˆæ¸¬ã§å¤§å¹…ãªç²¾åº¦åŠ£åŒ–ï¼ˆå®Ÿç”¨æ€§è¦æ¤œè¨ï¼‰")
    degradation_rate = (overall_mape - 2.54) / 2.54 * 100
    print(f"   ç²¾åº¦åŠ£åŒ–ç‡: {degradation_rate:.1f}%")

# %%
# ================================================================
# 7. æ—¥åˆ¥ç²¾åº¦åŠ£åŒ–ã®å¯è¦–åŒ–
# ================================================================

# æ—¥åˆ¥çµæœã‚’DataFrameã«å¤‰æ›
daily_df = pd.DataFrame(daily_results)

# æ—¥åˆ¥MAPEæ¨ç§»ã‚°ãƒ©ãƒ•
plt.figure(figsize=(12, 8))

plt.subplot(2, 2, 1)
plt.plot(daily_df['day'], daily_df['mape'], 'bo-', linewidth=2, markersize=6)
plt.axhline(y=2.54, color='r', linestyle='--', label='Phase 10ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ (2.54%)')
plt.title('ğŸ“ˆ æ—¥åˆ¥MAPEæ¨ç§»ï¼ˆæ®µéšçš„äºˆæ¸¬ï¼‰', fontsize=14, fontweight='bold')
plt.xlabel('Day')
plt.ylabel('MAPE (%)')
plt.grid(True, alpha=0.3)
plt.legend()

# æ—¥åˆ¥MAEæ¨ç§»ã‚°ãƒ©ãƒ•
plt.subplot(2, 2, 2)
plt.plot(daily_df['day'], daily_df['mae'], 'go-', linewidth=2, markersize=6)
plt.title('ğŸ“ˆ æ—¥åˆ¥MAEæ¨ç§»', fontsize=14, fontweight='bold')
plt.xlabel('Day')
plt.ylabel('MAE (ä¸‡kW)')
plt.grid(True, alpha=0.3)

# æ—¥åˆ¥RÂ²æ¨ç§»ã‚°ãƒ©ãƒ•
plt.subplot(2, 2, 3)
plt.plot(daily_df['day'], daily_df['r2'], 'mo-', linewidth=2, markersize=6)
plt.axhline(y=0.9839, color='r', linestyle='--', label='Phase 9ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ (0.9839)')
plt.title('ğŸ“ˆ æ—¥åˆ¥RÂ²æ¨ç§»', fontsize=14, fontweight='bold')
plt.xlabel('Day')
plt.ylabel('RÂ² Score')
plt.grid(True, alpha=0.3)
plt.legend()

# ç²¾åº¦åŠ£åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
plt.subplot(2, 2, 4)
mape_change = [(mape - daily_df['mape'].iloc[0]) for mape in daily_df['mape']]
plt.plot(daily_df['day'], mape_change, 'ro-', linewidth=2, markersize=6)
plt.title('ğŸ“‰ MAPEåŠ£åŒ–é‡ï¼ˆDay1æ¯”è¼ƒï¼‰', fontsize=14, fontweight='bold')
plt.xlabel('Day')
plt.ylabel('MAPEåŠ£åŒ–é‡ (%)')
plt.grid(True, alpha=0.3)
plt.axhline(y=0, color='k', linestyle='-', alpha=0.5)

plt.tight_layout()
plt.show()

# %%
# ================================================================
# 8. å®Ÿéš›ã®äºˆæ¸¬å€¤ vs å®Ÿç¸¾å€¤ã®æ¯”è¼ƒå¯è¦–åŒ–
# ================================================================

# æ™‚ç³»åˆ—ã§ã®äºˆæ¸¬å€¤vså®Ÿç¸¾å€¤æ¯”è¼ƒï¼ˆæœ€åˆã®3æ—¥é–“ï¼‰
sample_dates = pd.date_range('2025-06-01', '2025-06-03', freq='H')
sample_predictions = [predictions.get(dt, np.nan) for dt in sample_dates]
sample_actuals = [ml_features.loc[dt, 'actual_power'] if dt in ml_features.index else np.nan for dt in sample_dates]

plt.figure(figsize=(15, 6))
plt.plot(sample_dates, sample_actuals, 'b-', linewidth=2, label='å®Ÿç¸¾å€¤', alpha=0.8)
plt.plot(sample_dates, sample_predictions, 'r--', linewidth=2, label='æ®µéšçš„äºˆæ¸¬å€¤', alpha=0.8)
plt.title('ğŸ” æ®µéšçš„äºˆæ¸¬ vs å®Ÿç¸¾å€¤ï¼ˆ2025-06-01ã€œ03ï¼‰', fontsize=16, fontweight='bold')
plt.xlabel('æ—¥æ™‚')
plt.ylabel('é›»åŠ›éœ€è¦ï¼ˆä¸‡kWï¼‰')
plt.legend()
plt.grid(True, alpha=0.3)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# %%
# ================================================================
# 9. ç‰¹å¾´é‡é‡è¦åº¦åˆ†æï¼ˆæ¬ æå€¤è¾¼ã¿å­¦ç¿’ï¼‰
# ================================================================

print(f"\nğŸ“Š ç‰¹å¾´é‡é‡è¦åº¦åˆ†æï¼ˆdropna()ãªã—å­¦ç¿’ï¼‰:")
print(f"=" * 50)

# ç‰¹å¾´é‡é‡è¦åº¦å–å¾—
feature_importance = xgb_model.feature_importances_
importance_df = pd.DataFrame({
    'feature': features,
    'importance': feature_importance * 100
}).sort_values('importance', ascending=False)

# é‡è¦åº¦è¡¨ç¤º
for idx, row in importance_df.iterrows():
    rank = importance_df.index.get_loc(idx) + 1
    print(f"{rank:2d}. {row['feature']:19s}: {row['importance']:6.1f}%")

# %%
# ================================================================
# 10. åœŸæ—¥ç¥æ—¥ vs å¹³æ—¥ã®æ®µéšçš„äºˆæ¸¬ç²¾åº¦æ¯”è¼ƒ
# ================================================================

print(f"\n" + "="*50)
print("ğŸ“Š åœŸæ—¥ç¥æ—¥ vs å¹³æ—¥ã®æ®µéšçš„äºˆæ¸¬ç²¾åº¦æ¯”è¼ƒ")
print("="*50)

# æ®µéšçš„äºˆæ¸¬çµæœã«æ›œæ—¥æƒ…å ±è¿½åŠ 
weekday_analysis = []
weekend_analysis = []

for result in daily_results:
    date_obj = pd.to_datetime(result['date'])
    is_weekend = date_obj.weekday() >= 5
    
    # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç¥æ—¥åˆ¤å®š
    date_str = result['date']
    is_holiday = False
    if date_str in calendar_data.index:
        is_holiday = calendar_data.loc[date_str, 'is_holiday']
    
    day_info = {
        'date': result['date'],
        'mape': result['mape'],
        'mae': result['mae'],
        'r2': result['r2'],
        'day_type': 'åœŸæ—¥ç¥' if (is_weekend or is_holiday) else 'å¹³æ—¥'
    }
    
    if is_weekend or is_holiday:
        weekend_analysis.append(day_info)
    else:
        weekday_analysis.append(day_info)

# æ›œæ—¥åˆ¥ç²¾åº¦çµ±è¨ˆ
if len(weekday_analysis) > 0:
    weekday_mapes = [d['mape'] for d in weekday_analysis]
    weekday_avg_mape = np.mean(weekday_mapes)
    print(f"å¹³æ—¥ï¼ˆ{len(weekday_analysis)}æ—¥ï¼‰:")
    print(f"  å¹³å‡MAPE: {weekday_avg_mape:.2f}%")
    print(f"  MAPEç¯„å›²: {min(weekday_mapes):.2f}% ï½ {max(weekday_mapes):.2f}%")
    
if len(weekend_analysis) > 0:
    weekend_mapes = [d['mape'] for d in weekend_analysis]
    weekend_avg_mape = np.mean(weekend_mapes)
    print(f"åœŸæ—¥ç¥æ—¥ï¼ˆ{len(weekend_analysis)}æ—¥ï¼‰:")
    print(f"  å¹³å‡MAPE: {weekend_avg_mape:.2f}%")
    print(f"  MAPEç¯„å›²: {min(weekend_mapes):.2f}% ï½ {max(weekend_mapes):.2f}%")

# æ®µéšçš„äºˆæ¸¬ã§ã®åœŸæ—¥ç¥æ—¥å¯¾å¿œè©•ä¾¡
if len(weekday_analysis) > 0 and len(weekend_analysis) > 0:
    if weekend_avg_mape <= weekday_avg_mape * 1.15:  # 15%ä»¥å†…ã®å·®ã¯è¨±å®¹
        print(f"\nâœ… æ®µéšçš„äºˆæ¸¬ã§ã‚‚åœŸæ—¥ç¥æ—¥å¯¾å¿œæˆåŠŸ")
        print(f"âœ… å–¶æ¥­æ—¥lagæ¬ æå€¤ã®å½±éŸ¿ã‚’é©åˆ‡ã«å‡¦ç†")
    else:
        print(f"\nâš ï¸ æ®µéšçš„äºˆæ¸¬ã§åœŸæ—¥ç¥æ—¥ç²¾åº¦ãŒåŠ£åŒ–")
        print(f"âš ï¸ äºˆæ¸¬å€¤ä¾å­˜ã«ã‚ˆã‚Šæ¬ æå€¤å½±éŸ¿ãŒæ‹¡å¤§")

# %%
# ================================================================
# 11. å¤–ã‚Œå€¤æ¤œå‡ºãƒ»åˆ†æï¼ˆIQRæ³•ï¼‰
# ================================================================

print(f"\nğŸ“Š å¤–ã‚Œå€¤æ¤œå‡ºãƒ»åˆ†æ")
print(f"=" * 40)

# æ®‹å·®è¨ˆç®—
residuals = np.array(all_actuals) - np.array(all_predictions)
abs_residuals = np.abs(residuals)

# IQRæ³•ã«ã‚ˆã‚‹å¤–ã‚Œå€¤æ¤œå‡º
Q1 = np.percentile(abs_residuals, 25)
Q3 = np.percentile(abs_residuals, 75)
IQR = Q3 - Q1
outlier_threshold = Q3 + 1.5 * IQR

# å¤–ã‚Œå€¤ç‰¹å®š
outliers = abs_residuals > outlier_threshold
outliers_count = np.sum(outliers)

print(f"æ®‹å·®çµ±è¨ˆ:")
print(f"  Q1: {Q1:.2f}ä¸‡kW")
print(f"  Q3: {Q3:.2f}ä¸‡kW") 
print(f"  IQR: {IQR:.2f}ä¸‡kW")
print(f"  å¤–ã‚Œå€¤é–¾å€¤: {outlier_threshold:.2f}ä¸‡kW")
print(f"  å¤–ã‚Œå€¤: {outliers_count}ä»¶ ({outliers_count/len(abs_residuals)*100:.1f}%)")

# å¤–ã‚Œå€¤ã®è©³ç´°
if outliers_count > 0:
    outlier_datetimes = np.array(prediction_datetimes)[outliers]
    outlier_residuals = abs_residuals[outliers]
    print(f"\nå¤–ã‚Œå€¤è©³ç´°:")
    for i, (dt, residual) in enumerate(zip(outlier_datetimes, outlier_residuals)):
        print(f"  {i+1}. {dt}: æ®‹å·® {residual:.1f}ä¸‡kW")

# %%
# ================================================================
# 12. æ®µéšçš„äºˆæ¸¬å®Ÿé¨“çµæœã‚µãƒãƒªãƒ¼ãƒ»Phase 10è©•ä¾¡
# ================================================================

print(f"\n" + "ğŸ‰ æ®µéšçš„äºˆæ¸¬å®Ÿé¨“å®Œäº†ã‚µãƒãƒªãƒ¼" + "\n")
print("="*60)

print(f"âœ… æ®µéšçš„äºˆæ¸¬å®Ÿé¨“ï¼ˆdropna()ãªã—ï¼‰å®Œäº†")
print(f"âœ… äºˆæ¸¬æœŸé–“: 2025/6/1ï½6/16ï¼ˆ16æ—¥é–“ãƒ»384æ™‚é–“ï¼‰")
print(f"âœ… å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: 2025/5/31ã¾ã§ï¼ˆæ¬ æå€¤è¾¼ã¿ï¼‰")
print(f"âœ… XGBoostæ¬ æå€¤è‡ªå‹•å‡¦ç†ä½¿ç”¨")

print(f"\nğŸ“Š æ®µéšçš„äºˆæ¸¬ vs å›ºå®šäºˆæ¸¬ æ¯”è¼ƒçµæœ:")
print(f"=" * 50)
print(f"å›ºå®šäºˆæ¸¬ï¼ˆPhase 10ï¼‰: MAPE 2.54% ï¼ˆlagã‚’å®Ÿãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ï¼‰")
print(f"æ®µéšçš„äºˆæ¸¬ï¼ˆä»Šå›ï¼‰:   MAPE {overall_mape:.2f}% ï¼ˆlagã‚’äºˆæ¸¬å€¤ã§æ®µéšåŸ‹ã‚ï¼‰")

degradation_amount = overall_mape - 2.54
degradation_rate = degradation_amount / 2.54 * 100

if overall_mape <= 3.0:
    evaluation = "âœ… å®Ÿç”¨ãƒ¬ãƒ™ãƒ«ç¶­æŒ"
elif overall_mape <= 4.0:
    evaluation = "âš ï¸ è»½åº¦åŠ£åŒ–ãƒ»è¦æ³¨æ„"
else:
    evaluation = "âŒ å¤§å¹…åŠ£åŒ–ãƒ»è¦æ”¹å–„"

print(f"ç²¾åº¦åŠ£åŒ–é‡: +{degradation_amount:.2f}% ({degradation_rate:+.1f}%)")
print(f"å®Ÿç”¨æ€§è©•ä¾¡: {evaluation}")

print(f"\nğŸ“ˆ æ—¥åˆ¥ç²¾åº¦æ¨ç§»åˆ†æ:")
if len(daily_results) > 0:
    first_day_mape = daily_results[0]['mape']
    last_day_mape = daily_results[-1]['mape']
    max_mape = max([d['mape'] for d in daily_results])
    min_mape = min([d['mape'] for d in daily_results])
    
    print(f"åˆæ—¥MAPE: {first_day_mape:.2f}%")
    print(f"æœ€çµ‚æ—¥MAPE: {last_day_mape:.2f}%")
    print(f"æœ€å¤§MAPE: {max_mape:.2f}%")
    print(f"æœ€å°MAPE: {min_mape:.2f}%")
    print(f"ç²¾åº¦æ¨ç§»: {last_day_mape - first_day_mape:+.2f}% (åˆæ—¥â†’æœ€çµ‚æ—¥)")

print(f"\nğŸ¯ Phase 10ã‚·ã‚¹ãƒ†ãƒ åŒ–åˆ¤æ–­:")
if overall_mape <= 3.5:
    print(f"âœ… æ®µéšçš„äºˆæ¸¬ã§ã‚‚å®Ÿç”¨ãƒ¬ãƒ™ãƒ«é”æˆ")
    print(f"âœ… Phase 10æ—¥æ¬¡è‡ªå‹•äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰æ¨å¥¨")
    print(f"âœ… APIåˆ¶é™16æ—¥é–“ã§ã®é‹ç”¨å“è³ªç¢ºä¿")
else:
    print(f"âš ï¸ æ®µéšçš„äºˆæ¸¬ç²¾åº¦è¦æ”¹å–„")
    print(f"âš ï¸ Phase 10ã‚·ã‚¹ãƒ†ãƒ åŒ–å‰ã«ç²¾åº¦å‘ä¸Šç­–è¦æ¤œè¨")

print(f"\nğŸ“‹ Phase 10å®Œäº†æº–å‚™:")
print(f"âœ… åœŸæ—¥ç¥æ—¥æ¬ æå€¤å¯¾å¿œ: è§£æ±ºæ¸ˆã¿ï¼ˆMAPE 2.54%é”æˆï¼‰")
print(f"âœ… 16æ—¥é–“äºˆæ¸¬å¯¾å¿œ: APIåˆ¶é™å†…ã§é«˜ç²¾åº¦ç¢ºèª")
print(f"âœ… æ®µéšçš„äºˆæ¸¬æ¤œè¨¼: å®Ÿé‹ç”¨ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†")
print(f"â¡ï¸ æ¬¡ã‚¹ãƒ†ãƒƒãƒ—: æ—¥æ¬¡è‡ªå‹•äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ»Phase 11ç§»è¡Œ")

# %%
# ================================================================
# 13. ç‰¹å¾´é‡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æï¼ˆå®Ÿé‹ç”¨ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
# ================================================================

print(f"\nğŸ“‹ æ®µéšçš„äºˆæ¸¬ã§ã®ç‰¹å¾´é‡ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ")
print("="*60)

# å„æ—¥ã§ã®ç‰¹å¾´é‡ã‚½ãƒ¼ã‚¹åˆ†æä¾‹
pattern_analysis_examples = {
    '6/1 0:00': {
        'lag_1_day': '5/31 0:00å®Ÿãƒ‡ãƒ¼ã‚¿',
        'lag_7_day': '5/25 0:00å®Ÿãƒ‡ãƒ¼ã‚¿',  
        'lag_1_business_day': '5/30 0:00å®Ÿãƒ‡ãƒ¼ã‚¿ï¼ˆé‡‘æ›œæ—¥ï¼‰'
    },
    '6/1 1:00': {
        'lag_1_day': '5/31 1:00å®Ÿãƒ‡ãƒ¼ã‚¿',
        'lag_7_day': '5/25 1:00å®Ÿãƒ‡ãƒ¼ã‚¿',
        'lag_1_business_day': '5/30 1:00å®Ÿãƒ‡ãƒ¼ã‚¿'
    },
    '6/2 0:00': {
        'lag_1_day': '6/1 0:00äºˆæ¸¬å€¤ï¼ˆâ†æ®µéšçš„äºˆæ¸¬é–‹å§‹ï¼‰',
        'lag_7_day': '5/26 0:00å®Ÿãƒ‡ãƒ¼ã‚¿',
        'lag_1_business_day': '6/1 0:00äºˆæ¸¬å€¤ï¼ˆæœˆæ›œæ—¥â†’é‡‘æ›œæ—¥ï¼‰'
    },
    '6/8 0:00': {
        'lag_1_day': '6/7 0:00äºˆæ¸¬å€¤',
        'lag_7_day': '6/1 0:00äºˆæ¸¬å€¤ï¼ˆâ†7æ—¥å‰ã‚‚äºˆæ¸¬å€¤ã«ï¼‰',
        'lag_1_business_day': '6/7 0:00äºˆæ¸¬å€¤ï¼ˆåœŸæ›œâ†’é‡‘æ›œï¼‰'
    }
}

print("æ®µéšçš„äºˆæ¸¬ã§ã®ç‰¹å¾´é‡ã‚½ãƒ¼ã‚¹æ¨ç§»:")
for datetime_key, sources in pattern_analysis_examples.items():
    print(f"\n{datetime_key}:")
    for feature, source in sources.items():
        print(f"  {feature:20s}: {source}")

print(f"\nğŸ’¡ å®Ÿé‹ç”¨ã§ã®ç²¾åº¦åŠ£åŒ–è¦å› :")
print(f"  1. åˆæ—¥: å®Ÿãƒ‡ãƒ¼ã‚¿lagè±Šå¯Œâ†’é«˜ç²¾åº¦")
print(f"  2. 2æ—¥ç›®ä»¥é™: lag_1_dayäºˆæ¸¬å€¤ä¾å­˜â†’å¾ã€…ã«åŠ£åŒ–")
print(f"  3. 8æ—¥ç›®ä»¥é™: lag_7_dayäºˆæ¸¬å€¤ä¾å­˜â†’ã•ã‚‰ã«åŠ£åŒ–")
print(f"  4. å–¶æ¥­æ—¥å¤‰åŒ–: lag_1_business_dayäºˆæ¸¬å€¤æ··å…¥â†’èª¤å·®æ‹¡å¤§")

# %%
# ================================================================
# 14. Phase 10å®Ÿé¨“å®Œäº†ãƒ»æ¬¡æ®µéšæº–å‚™
# ================================================================

print(f"\nğŸš€ Phase 10æ®µéšçš„äºˆæ¸¬å®Ÿé¨“å®Œäº†")
print("="*60)

print(f"ã€å®Ÿé¨“æˆæœã€‘")
print(f"âœ… æ®µéšçš„äºˆæ¸¬ç²¾åº¦: MAPE {overall_mape:.2f}%")
print(f"âœ… å‰å›å›ºå®šäºˆæ¸¬ã‹ã‚‰ã®åŠ£åŒ–: +{degradation_amount:.2f}%")
print(f"âœ… å¤–ã‚Œå€¤: {outliers_count}ä»¶ ({outliers_count/len(abs_residuals)*100:.1f}%)")
print(f"âœ… åœŸæ—¥ç¥æ—¥å¯¾å¿œ: dropna()ãªã—ã§ã‚‚å®‰å®šé‹ç”¨")

print(f"\nã€é‡è¦ãªç™ºè¦‹ã€‘")
print(f"ğŸ” å®Ÿé‹ç”¨ã§ã®äºˆæ¸¬å€¤ä¾å­˜ã«ã‚ˆã‚‹ç²¾åº¦å¤‰åŒ–ã‚’å®šé‡æ¸¬å®š")
print(f"ğŸ” XGBoostæ¬ æå€¤è‡ªå‹•å‡¦ç†ã®æ®µéšçš„äºˆæ¸¬ã§ã®æœ‰åŠ¹æ€§ç¢ºèª")
print(f"ğŸ” 16æ—¥é–“äºˆæ¸¬ã§ã®æ—¥åˆ¥ç²¾åº¦åŠ£åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³æŠŠæ¡")

print(f"\nã€Phase 10å®Œäº†åˆ¤æ–­ã€‘")
if overall_mape <= 3.5:
    print(f"âœ… MAPE {overall_mape:.2f}% - å®Ÿç”¨ãƒ¬ãƒ™ãƒ«é”æˆ")
    print(f"âœ… Phase 10æ—¥æ¬¡è‡ªå‹•äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰OK")
    print(f"âœ… Phase 11 Looker Studioãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç§»è¡ŒOK")
else:
    print(f"âš ï¸ MAPE {overall_mape:.2f}% - ç²¾åº¦å‘ä¸Šç­–è¦æ¤œè¨")
    print(f"âš ï¸ Phase 10ã‚·ã‚¹ãƒ†ãƒ åŒ–å‰ã«è¿½åŠ æ”¹è‰¯æ¨å¥¨")

print(f"\nã€æ¬¡ã‚¹ãƒ†ãƒƒãƒ—æº–å‚™å®Œäº†ã€‘")
print(f"ğŸ¯ æ—¥æ¬¡è‡ªå‹•äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ")
print(f"ğŸ¯ PowerDataDownloader + WeatherDownloaderçµ±åˆ")
print(f"ğŸ¯ Phase 5-6ç‰¹å¾´é‡ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯çµ±åˆ")
print(f"ğŸ¯ Phase 9 XGBoostãƒ¢ãƒ‡ãƒ«ï¼ˆåœŸæ—¥ç¥æ—¥å¯¾å¿œï¼‰çµ±åˆ")
print(f"ğŸ¯ BigQueryçµæœä¿å­˜ãƒ»Looker Studioæº–å‚™")

print(f"\nğŸ‰ Phase 10æ®µéšçš„äºˆæ¸¬å®Ÿé¨“å®Œäº†ï¼")
print(f"âœ¨ å®Ÿé‹ç”¨ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æˆåŠŸãƒ»ã‚·ã‚¹ãƒ†ãƒ åŒ–æº–å‚™å®Œäº†ï¼")


# %%
# ================================================================
# 6/1 0:00 äºˆæ¸¬å€¤ç¢ºèªï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰
# ================================================================

# æ®µéšçš„äºˆæ¸¬ã®6/1 0:00ç¢ºèªç”¨ã‚³ãƒ¼ãƒ‰
target_datetime = pd.to_datetime('2025-06-01 00:00:00')
iterative_pred = predictions[target_datetime]
actual_value = 2131.00  # å®Ÿç¸¾å€¤ï¼ˆå›ºå®šäºˆæ¸¬ã¨åŒã˜ï¼‰

print(f"6/1 0:00ã®æ®µéšçš„äºˆæ¸¬çµæœ:")
print(f"æ®µéšçš„äºˆæ¸¬å€¤: {iterative_pred:.2f}ä¸‡kW")
print(f"å®Ÿç¸¾å€¤:       {actual_value:.2f}ä¸‡kW")
print(f"èª¤å·®:         {abs(iterative_pred - actual_value):.2f}ä¸‡kW")
print(f"èª¤å·®ç‡:       {abs(iterative_pred - actual_value) / actual_value * 100:.2f}%")

print(f"\nğŸ“Š å›ºå®š vs æ®µéšçš„ æ¯”è¼ƒ:")
print(f"å›ºå®šäºˆæ¸¬:   2154.15ä¸‡kW (èª¤å·®ç‡1.09%)")
print(f"æ®µéšçš„äºˆæ¸¬: {iterative_pred:.2f}ä¸‡kW (èª¤å·®ç‡?%)")
print(f"äºˆæ¸¬å€¤å·®:   {abs(2154.15 - iterative_pred):.2f}ä¸‡kW")

# %%
# ================================================================
# 6/1 0:00 ç‰¹å¾´é‡æº–å‚™ å˜ä½“ç¢ºèª
# ================================================================

target_datetime = pd.to_datetime('2025-06-01 00:00:00')
empty_predictions = {}  # åˆå›ãªã®ã§ç©ºã®è¾æ›¸

print("ğŸ” 6/1 0:00ã®ç‰¹å¾´é‡æº–å‚™ç¢ºèª:")
print("=" * 60)

# ç‰¹å¾´é‡æº–å‚™å®Ÿè¡Œï¼ˆãƒ‡ãƒãƒƒã‚°ç‰ˆï¼‰
feature_values = prepare_features_for_prediction_debug(target_datetime, empty_predictions)

print("\nğŸ“‹ æº–å‚™ã•ã‚ŒãŸç‰¹å¾´é‡å€¤:")
for i, (feat_name, feat_val) in enumerate(zip(features, feature_values)):
    print(f"  {i+1:2d}. {feat_name:20s}: {feat_val}")

# %%