"""
æ°—è±¡ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼ - Open-Meteo APIçµ±åˆï¼ˆä¿®æ­£ç‰ˆï¼‰

Phase 10: æ—¥æ¬¡è‡ªå‹•äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ç”¨
- Historical API: éå»ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆ2æ—¥é…å»¶è€ƒæ…®ï¼‰
- Forecast API: 16æ—¥é–“ã®äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿å–å¾—
- åŸºæº–æ—¥ã«ã‚ˆã‚‹å–å¾—ãƒ­ã‚¸ãƒƒã‚¯åˆ†é›¢

å®Ÿè¡Œæ–¹æ³•:
    # æ—¥æ¬¡è‡ªå‹•å®Ÿè¡Œç”¨ï¼ˆéå»10æ—¥+äºˆæ¸¬16æ—¥ï¼‰
    python -m src.data_processing.weather_downloader

    # éå»ãƒ‡ãƒ¼ã‚¿åˆ†æç”¨ï¼ˆæŒ‡å®šæ—¥ã‹ã‚‰30æ—¥å‰ã¾ã§ï¼‰
    python -m src.data_processing.weather_downloader --date 2025-08-01

    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæŒ‡å®š
    python -m src.data_processing.weather_downloader --download-dir data/weather/raw/daily
"""

import os
import json
import requests
import argparse
import time
import uuid
from datetime import datetime, timedelta
from pathlib import Path
from google.cloud import bigquery

class WeatherDownloader:
    """Open-Meteo APIæ°—è±¡ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼"""
    
    # API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    HISTORICAL_URL = "https://archive-api.open-meteo.com/v1/archive"
    FORECAST_URL = "https://api.open-meteo.com/v1/forecast"
    
    # åƒè‘‰çœŒåº§æ¨™ï¼ˆPhase 9ã§æœ€é‡è¦åœ°ç‚¹ã¨ã—ã¦ç¢ºå®šï¼‰
    CHIBA_COORDS = {
        'latitude': 35.6047,
        'longitude': 140.1233
    }
    
    # å–å¾—ã™ã‚‹æ°—è±¡å¤‰æ•°ï¼ˆWeatherProcessoräº’æ›ï¼‰
    WEATHER_VARIABLES = [
        'temperature_2m',
        'relative_humidity_2m', 
        'precipitation',
        'weather_code'
    ]
    
    def __init__(self, download_dir=None):
        """
        åˆæœŸåŒ–

        Args:
            download_dir (str): JSONãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
        energy_env_path = os.getenv('ENERGY_ENV_PATH')
        if energy_env_path is None:
            raise ValueError("ENERGY_ENV_PATHç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

        if download_dir is None:
            download_dir = os.path.join(energy_env_path, 'data', 'weather', 'raw', 'daily')
            self.log_dir = Path(energy_env_path) / 'logs' / 'weather_api'
        else:
            self.log_dir = Path(download_dir).parent.parent.parent / 'logs' / 'weather_api'

        self.download_dir = Path(download_dir)
        self.download_dir.mkdir(parents=True, exist_ok=True)
        self.log_dir.mkdir(parents=True, exist_ok=True)

        # BigQueryè¨­å®š
        self.bq_client = bigquery.Client()
        self.bq_table_id = "energy-env.prod_energy_data.process_execution_log"

        print(f"WeatherDownloaderåˆæœŸåŒ–å®Œäº† ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å…ˆ: {self.download_dir}")

    def _write_log(self, log_data):
        """
        ãƒ­ã‚°ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¨BigQueryã«è¨˜éŒ²

        Args:
            log_data (dict): ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿
        """
        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨˜éŒ²
        log_date = log_data.get('date', datetime.now().strftime('%Y-%m-%d'))
        log_file = self.log_dir / f"{log_date}_weather_execution.jsonl"

        try:
            with open(log_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(log_data, ensure_ascii=False) + '\n')
        except Exception as e:
            print(f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿å¤±æ•—: {e}")

        # BigQueryã«è¨˜éŒ²
        try:
            self.bq_client.insert_rows_json(self.bq_table_id, [log_data])
        except Exception as e:
            # BQã‚¨ãƒ©ãƒ¼ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ãƒ­ã‚°ã«ã‚‚è¨˜éŒ²
            error_log = {
                'timestamp': datetime.now().isoformat(),
                'error_type': 'BQ_INSERT_FAILED',
                'error_message': str(e),
                'original_log_data': log_data
            }
            error_log_file = self.log_dir / f"{log_date}_bq_errors.jsonl"
            try:
                with open(error_log_file, 'a', encoding='utf-8') as f:
                    f.write(json.dumps(error_log, ensure_ascii=False) + '\n')
            except Exception as file_error:
                print(f"ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿å¤±æ•—: {file_error}")

            print(f"BigQueryæ›¸ãè¾¼ã¿å¤±æ•—ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ä¿å­˜æ¸ˆã¿ãƒ»ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°è¨˜éŒ²æ¸ˆã¿ï¼‰: {e}")

    def download_with_retry(self, session, url, params, max_retries=3):
        """
        ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãAPIãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        
        Args:
            session (requests.Session): HTTPã‚»ãƒƒã‚·ãƒ§ãƒ³
            url (str): APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆURL
            params (dict): ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            max_retries (int): æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°
            
        Returns:
            requests.Response: HTTPãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            
        Raises:
            Exception: ãƒªãƒˆãƒ©ã‚¤å›æ•°è¶…éæ™‚
        """
        for attempt in range(max_retries):
            try:
                response = session.get(url, params=params, timeout=30)
                
                if response.status_code == 200:
                    return response
                elif response.status_code == 429:  # Too Many Requests
                    wait_time = 2 ** attempt  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                    print(f"ãƒ¬ãƒ¼ãƒˆåˆ¶é™æ¤œçŸ¥ã€{wait_time}ç§’å¾…æ©Ÿä¸­... (è©¦è¡Œ {attempt + 1}å›ç›®)")
                    time.sleep(wait_time)
                    continue
                else:
                    response.raise_for_status()

            except requests.exceptions.RequestException as e:
                print(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•— (è©¦è¡Œ {attempt + 1}å›ç›®): {e}")
                if attempt == max_retries - 1:
                    raise
                time.sleep(1)
        
        raise Exception(f"Failed to get response after {max_retries} attempts")
    
    def get_historical_data(self, session, start_date, end_date):
        """
        Historical API ã§éå»ãƒ‡ãƒ¼ã‚¿å–å¾—
        
        Args:
            session (requests.Session): HTTPã‚»ãƒƒã‚·ãƒ§ãƒ³
            start_date (str): é–‹å§‹æ—¥ (YYYY-MM-DD)
            end_date (str): çµ‚äº†æ—¥ (YYYY-MM-DD)
            
        Returns:
            requests.Response: HTTPãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        params = {
            'latitude': self.CHIBA_COORDS['latitude'],
            'longitude': self.CHIBA_COORDS['longitude'],
            'start_date': start_date,
            'end_date': end_date,
            'hourly': ','.join(self.WEATHER_VARIABLES),
            'timezone': 'Asia/Tokyo'
        }
        
        print(f"éå»ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {start_date} ï½ {end_date}")
        return self.download_with_retry(session, self.HISTORICAL_URL, params)
    
    def get_forecast_data(self, session, forecast_days=16):
        """
        Forecast API ã§äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿å–å¾—
        
        Args:
            session (requests.Session): HTTPã‚»ãƒƒã‚·ãƒ§ãƒ³
            forecast_days (int): äºˆæ¸¬æ—¥æ•°ï¼ˆæœ€å¤§16æ—¥ï¼‰
            
        Returns:
            requests.Response: HTTPãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        params = {
            'latitude': self.CHIBA_COORDS['latitude'],
            'longitude': self.CHIBA_COORDS['longitude'],
            'hourly': ','.join(self.WEATHER_VARIABLES),
            'forecast_days': min(forecast_days, 16),  # åˆ¶é™å¯¾å¿œ
            'timezone': 'Asia/Tokyo'
        }
        
        print(f"äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {forecast_days}æ—¥åˆ†")
        return self.download_with_retry(session, self.FORECAST_URL, params)
    
    def save_json_response(self, response, filename):
        """
        APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç›´æ¥JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ï¼ˆç„¡é§„ãªå¤‰æ›ãªã—ï¼‰

        Args:
            response (requests.Response): APIãƒ¬ã‚¹ãƒãƒ³ã‚¹
            filename (str): å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å

        Returns:
            str: ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        output_path = self.download_dir / filename
        
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(response.text)  # APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç›´æ¥ä¿å­˜

            print(f"æ°—è±¡ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: {output_path}")
            return str(output_path)

        except Exception as e:
            print(f"JSONãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å¤±æ•— {output_path}: {e}")
            raise
    
    def validate_response(self, response):
        """
        APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®åŸºæœ¬æ¤œè¨¼ï¼ˆJSONå½¢å¼ãƒã‚§ãƒƒã‚¯ï¼‰
        
        Args:
            response (requests.Response): APIãƒ¬ã‚¹ãƒãƒ³ã‚¹
            
        Returns:
            dict: æ¤œè¨¼çµæœ
        """
        validation_result = {
            'valid': True,
            'issues': [],
            'stats': {}
        }
        
        try:
            # JSONå½¢å¼ãƒã‚§ãƒƒã‚¯ï¼ˆå¿…è¦æ™‚ã®ã¿å¤‰æ›ï¼‰
            data = response.json()
            
            # åŸºæœ¬æ§‹é€ ãƒã‚§ãƒƒã‚¯
            if 'hourly' not in data:
                validation_result['valid'] = False
                validation_result['issues'].append("Missing 'hourly' data")
                return validation_result
            
            hourly_data = data['hourly']
            
            # æ°—è±¡å¤‰æ•°å­˜åœ¨ãƒã‚§ãƒƒã‚¯
            missing_vars = []
            for var in self.WEATHER_VARIABLES:
                if var not in hourly_data:
                    missing_vars.append(var)
            
            if missing_vars:
                validation_result['valid'] = False
                validation_result['issues'].append(f"Missing variables: {missing_vars}")
            
            # ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°ã‚«ã‚¦ãƒ³ãƒˆ
            if 'time' in hourly_data:
                validation_result['stats']['total_hours'] = len(hourly_data['time'])
            
        except json.JSONDecodeError as e:
            validation_result['valid'] = False
            validation_result['issues'].append(f"JSON decode error: {e}")
        except Exception as e:
            validation_result['valid'] = False
            validation_result['issues'].append(f"Validation error: {e}")
        
        return validation_result
    
    def download_daily_weather_data(self, target_date=None):
        """
        æ—¥æ¬¡æ°—è±¡ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆä¿®æ­£ç‰ˆï¼‰
        
        Args:
            target_date (str): åŸºæº–æ—¥ (YYYY-MM-DDå½¢å¼)
                             None: æ—¥æ¬¡è‡ªå‹•å®Ÿè¡Œç”¨ï¼ˆéå»10æ—¥+äºˆæ¸¬16æ—¥ï¼‰
                             æŒ‡å®š: éå»ãƒ‡ãƒ¼ã‚¿åˆ†æç”¨ï¼ˆæŒ‡å®šæ—¥ã‹ã‚‰30æ—¥å‰ã¾ã§ï¼‰
        
        Returns:
            dict: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çµæœ
        """
        today = datetime.now()
        
        if target_date is None:
            # ã‚±ãƒ¼ã‚¹1: åŸºæº–æ—¥ç„¡ã—ï¼ˆæ—¥æ¬¡è‡ªå‹•å®Ÿè¡Œç”¨ï¼‰
            execution_id = str(uuid.uuid4())
            started_at = datetime.now()
            target_date_str = started_at.strftime('%Y-%m-%d')

            print("æ—¥æ¬¡è‡ªå‹•å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: éå»ãƒ‡ãƒ¼ã‚¿(10æ—¥å‰ï½3æ—¥å‰) + äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿(16æ—¥é–“)")

            # éå»ãƒ‡ãƒ¼ã‚¿: 10æ—¥å‰ã‹ã‚‰3æ—¥å‰ã¾ã§ï¼ˆAPIé…å»¶è€ƒæ…®ï¼‰
            historical_start = (today - timedelta(days=10)).strftime('%Y-%m-%d')
            historical_end = (today - timedelta(days=3)).strftime('%Y-%m-%d')

            # ãƒ•ã‚¡ã‚¤ãƒ«åç”¨ã®æ—¥ä»˜ï¼ˆä»Šæ—¥ï¼‰
            date_part = today.strftime('%m%d')
            year = today.year

            # HTTPã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆãƒ»ãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®š
            session = requests.Session()
            session.headers.update({
                'User-Agent': 'energy-env-weather-downloader/1.0',
                'Accept': 'application/json'
            })
            results = {'historical': [], 'forecast': []}

            try:
                # 1. éå»ãƒ‡ãƒ¼ã‚¿å–å¾—
                historical_response = self.get_historical_data(session, historical_start, historical_end)
                
                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ¤œè¨¼
                validation = self.validate_response(historical_response)
                if not validation['valid']:
                        print(f"éå»ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼å•é¡Œ: {validation['issues']}")
                
                # ãƒ•ã‚¡ã‚¤ãƒ«å: chiba_2025_0818_historical.json
                historical_filename = f"chiba_{year}_{date_part}_historical.json"
                historical_path = self.save_json_response(historical_response, historical_filename)
                
                results['historical'].append({
                    'file': historical_path,
                    'period': f"{historical_start} to {historical_end}",
                    'data_points': validation['stats'].get('total_hours', 0) if validation['valid'] else 0,
                    'validation': validation
                })
                
                # 2. äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿å–å¾—
                forecast_response = self.get_forecast_data(session, forecast_days=16)
                
                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ¤œè¨¼
                validation = self.validate_response(forecast_response)
                if not validation['valid']:
                        print(f"äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼å•é¡Œ: {validation['issues']}")
                
                # ãƒ•ã‚¡ã‚¤ãƒ«å: chiba_2025_0818_forecast.json
                forecast_filename = f"chiba_{year}_{date_part}_forecast.json"
                forecast_path = self.save_json_response(forecast_response, forecast_filename)
                
                results['forecast'].append({
                    'file': forecast_path,
                    'forecast_days': 16,
                    'data_points': validation['stats'].get('total_hours', 0) if validation['valid'] else 0,
                    'validation': validation
                })
                
                # æˆåŠŸãƒ­ã‚°è¨˜éŒ²
                completed_at = datetime.now()
                duration_seconds = int((completed_at - started_at).total_seconds())
                total_data_points = sum([item['data_points'] for item in results['historical']]) + \
                                   sum([item['data_points'] for item in results['forecast']])

                log_data = {
                    "execution_id": execution_id,
                    "date": target_date_str,
                    "process_type": "WEATHER_API",
                    "status": "SUCCESS",
                    "error_message": None,
                    "started_at": started_at.isoformat(),
                    "completed_at": completed_at.isoformat(),
                    "duration_seconds": duration_seconds,
                    "records_processed": total_data_points,
                    "file_size_mb": None,
                    "additional_info": {
                        "mode": "daily_automatic",
                        "historical_period": f"{historical_start} to {historical_end}",
                        "forecast_days": 16,
                        "historical_files": len(results['historical']),
                        "forecast_files": len(results['forecast'])
                    }
                }

                self._write_log(log_data)
                print("æ—¥æ¬¡è‡ªå‹•æ°—è±¡ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")
                return results

            except Exception as e:
                # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°è¨˜éŒ²
                completed_at = datetime.now()
                duration_seconds = int((completed_at - started_at).total_seconds())

                log_data = {
                    "execution_id": execution_id,
                    "date": target_date_str,
                    "process_type": "WEATHER_API",
                    "status": "FAILED",
                    "error_message": str(e),
                    "started_at": started_at.isoformat(),
                    "completed_at": completed_at.isoformat(),
                    "duration_seconds": duration_seconds,
                    "records_processed": None,
                    "file_size_mb": None,
                    "additional_info": {
                        "mode": "daily_automatic",
                        "historical_period": f"{historical_start} to {historical_end}",
                        "forecast_days": 16
                    }
                }

                self._write_log(log_data)
                print(f"æ—¥æ¬¡è‡ªå‹•æ°—è±¡ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
                raise
            finally:
                session.close()
        
        else:
            # ã‚±ãƒ¼ã‚¹2: åŸºæº–æ—¥æŒ‡å®šï¼ˆéå»ãƒ‡ãƒ¼ã‚¿åˆ†æç”¨ï¼‰
            try:
                target_dt = datetime.strptime(target_date, '%Y-%m-%d')
            except ValueError:
                raise ValueError(f"Invalid date format. Use YYYY-MM-DD format.")

            execution_id = str(uuid.uuid4())
            started_at = datetime.now()
            target_date_str = target_date

            print(f"éå»ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ¢ãƒ¼ãƒ‰: {target_date} ã‹ã‚‰30æ—¥å‰ã¾ã§")
            
            # éå»ãƒ‡ãƒ¼ã‚¿: æŒ‡å®šæ—¥ã‹ã‚‰30æ—¥å‰ã¾ã§
            historical_start = (target_dt - timedelta(days=30)).strftime('%Y-%m-%d')
            historical_end = target_date
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åç”¨ã®æ—¥ä»˜ï¼ˆæŒ‡å®šæ—¥ï¼‰
            date_part = target_dt.strftime('%m%d')
            year = target_dt.year

            # HTTPã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆãƒ»ãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®š
            session = requests.Session()
            session.headers.update({
                'User-Agent': 'energy-env-weather-downloader/1.0',
                'Accept': 'application/json'
            })
            results = {'historical': [], 'forecast': []}
            
            try:
                # éå»ãƒ‡ãƒ¼ã‚¿ã®ã¿å–å¾—
                historical_response = self.get_historical_data(session, historical_start, historical_end)
                
                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ¤œè¨¼
                validation = self.validate_response(historical_response)
                if not validation['valid']:
                        print(f"éå»ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼å•é¡Œ: {validation['issues']}")
                
                # ãƒ•ã‚¡ã‚¤ãƒ«å: chiba_2025_0801_historical_30days.json
                historical_filename = f"chiba_{year}_{date_part}_historical_30days.json"
                historical_path = self.save_json_response(historical_response, historical_filename)
                
                results['historical'].append({
                    'file': historical_path,
                    'period': f"{historical_start} to {historical_end}",
                    'data_points': validation['stats'].get('total_hours', 0) if validation['valid'] else 0,
                    'validation': validation
                })
                
                # æˆåŠŸãƒ­ã‚°è¨˜éŒ²
                completed_at = datetime.now()
                duration_seconds = int((completed_at - started_at).total_seconds())
                total_data_points = sum([item['data_points'] for item in results['historical']])

                log_data = {
                    "execution_id": execution_id,
                    "date": target_date_str,
                    "process_type": "WEATHER_API",
                    "status": "SUCCESS",
                    "error_message": None,
                    "started_at": started_at.isoformat(),
                    "completed_at": completed_at.isoformat(),
                    "duration_seconds": duration_seconds,
                    "records_processed": total_data_points,
                    "file_size_mb": None,
                    "additional_info": {
                        "mode": "historical_analysis",
                        "historical_period": f"{historical_start} to {historical_end}",
                        "historical_files": len(results['historical'])
                    }
                }

                self._write_log(log_data)
                print(f"éå»ãƒ‡ãƒ¼ã‚¿åˆ†æç”¨æ°—è±¡ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {target_date}")
                return results

            except Exception as e:
                # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°è¨˜éŒ²
                completed_at = datetime.now()
                duration_seconds = int((completed_at - started_at).total_seconds())

                log_data = {
                    "execution_id": execution_id,
                    "date": target_date_str,
                    "process_type": "WEATHER_API",
                    "status": "FAILED",
                    "error_message": str(e),
                    "started_at": started_at.isoformat(),
                    "completed_at": completed_at.isoformat(),
                    "duration_seconds": duration_seconds,
                    "records_processed": None,
                    "file_size_mb": None,
                    "additional_info": {
                        "mode": "historical_analysis",
                        "historical_period": f"{historical_start} to {historical_end}"
                    }
                }

                self._write_log(log_data)
                print(f"éå»ãƒ‡ãƒ¼ã‚¿åˆ†æç”¨æ°—è±¡ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
                raise
            finally:
                session.close()


def print_results(results):
    """å‡¦ç†çµæœã‚’è¡¨ç¤º"""
    print(f"\n{'='*60}")
    print("ğŸŒ¤ï¸ æ°—è±¡ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çµæœ")
    print('='*60)
    
    # Historical ãƒ‡ãƒ¼ã‚¿çµæœ
    if results['historical']:
        print(f"\nâœ… éå»ãƒ‡ãƒ¼ã‚¿: {len(results['historical'])}ä»¶")
        for item in results['historical']:
            print(f"  ğŸ“ {Path(item['file']).name}")
            print(f"     æœŸé–“: {item['period']}")
            print(f"     ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ: {item['data_points']}æ™‚é–“")
            if not item['validation']['valid']:
                print(f"     âš ï¸ æ¤œè¨¼å•é¡Œ: {item['validation']['issues']}")
    
    # Forecast ãƒ‡ãƒ¼ã‚¿çµæœ
    if results['forecast']:
        print(f"\nâœ… äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿: {len(results['forecast'])}ä»¶")
        for item in results['forecast']:
            print(f"  ğŸ“ {Path(item['file']).name}")
            print(f"     äºˆæ¸¬æœŸé–“: {item['forecast_days']}æ—¥é–“")
            print(f"     ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ: {item['data_points']}æ™‚é–“")
            if not item['validation']['valid']:
                print(f"     âš ï¸ æ¤œè¨¼å•é¡Œ: {item['validation']['issues']}")
    
    print(f"\nğŸ“ˆ ç·åˆçµæœ: éå»{len(results['historical'])}ä»¶ / äºˆæ¸¬{len(results['forecast'])}ä»¶")
    print('='*60)


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description='Open-Meteoæ°—è±¡ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼ï¼ˆä¿®æ­£ç‰ˆï¼‰')
    parser.add_argument('--date', type=str,
                       help='åŸºæº–æ—¥ (YYYY-MM-DDå½¢å¼) æŒ‡å®šãªã—:æ—¥æ¬¡è‡ªå‹•å®Ÿè¡Œç”¨ã€æŒ‡å®šã‚ã‚Š:éå»ãƒ‡ãƒ¼ã‚¿åˆ†æç”¨')
    parser.add_argument('--download-dir', type=str,
                       help='ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹')
    
    args = parser.parse_args()
    
    print("ğŸš€ Open-Meteoæ°—è±¡ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹")
    print(f"ğŸ“ å¯¾è±¡åœ°ç‚¹: åƒè‘‰çœŒ (lat: {WeatherDownloader.CHIBA_COORDS['latitude']}, "
          f"lon: {WeatherDownloader.CHIBA_COORDS['longitude']})")
    
    if args.date:
        print(f"ğŸ“… åŸºæº–æ—¥æŒ‡å®š: {args.date} (éå»ãƒ‡ãƒ¼ã‚¿åˆ†æç”¨)")
        print(f"ğŸ“Š å–å¾—ç¯„å›²: {args.date}ã‹ã‚‰30æ—¥å‰ã¾ã§ã®éå»ãƒ‡ãƒ¼ã‚¿")
    else:
        today = datetime.now()
        historical_start = (today - timedelta(days=10)).strftime('%Y-%m-%d')
        historical_end = (today - timedelta(days=3)).strftime('%Y-%m-%d')
        print(f"ğŸ“… æ—¥æ¬¡è‡ªå‹•å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰")
        print(f"ğŸ“Š å–å¾—ç¯„å›²: éå»ãƒ‡ãƒ¼ã‚¿({historical_start}ã€œ{historical_end}) + äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿(16æ—¥é–“)")
    
    try:
        # WeatherDownloaderåˆæœŸåŒ–
        downloader = WeatherDownloader(args.download_dir)
        
        # æ°—è±¡ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
        results = downloader.download_daily_weather_data(args.date)
        
        # çµæœè¡¨ç¤º
        print_results(results)
        
    except Exception as e:
        print(f"ğŸ’¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    print("ğŸ æ°—è±¡ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")


if __name__ == "__main__":
    main()