"""
æ°—è±¡ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ - JSONâ†’CSVå¤‰æ›ãƒ»BigQueryæŠ•å…¥æº–å‚™

å®Ÿè¡Œæ–¹æ³•:
    python -m src.data_processing.weather_processor --input-dir data/weather/raw/historical
    python -m src.data_processing.weather_processor --input-dir data/weather/raw/historical --date 2025-07-13
"""

import os
import json
import csv
import argparse
from datetime import datetime
from pathlib import Path
from logging import getLogger

from src.utils.logging_config import setup_logging

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å°‚ç”¨ã®ãƒ­ã‚¬ãƒ¼ã‚’å–å¾—
logger = getLogger('energy_env.data_processing.weather_processor')

class WeatherProcessor:
    """æ°—è±¡ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼"""
    
    # æœ‰åŠ¹ãªéƒ½çœŒãƒªã‚¹ãƒˆ
    VALID_PREFECTURES = [
        'tokyo', 'kanagawa', 'saitama', 'chiba', 'ibaraki', 
        'tochigi', 'gunma', 'yamanashi', 'shizuoka'
    ]
    
    def __init__(self, output_dir="data/weather/processed/forecast"):
        """
        åˆæœŸåŒ–
        
        Args:
            output_dir (str): CSVå‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        logger.info(f"WeatherProcessor initialized with output_dir: {self.output_dir}")
    
    def convert_json_to_csv(self, json_file_path, date_filter=None):
        """
        JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’CSVã«å¤‰æ›
        
        Args:
            json_file_path (str): å…¥åŠ›JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            date_filter (str, optional): æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ (YYYY-MM-DDå½¢å¼)
            
        Returns:
            str: å‡ºåŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯Noneï¼‰
        """
        json_path = Path(json_file_path)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰éƒ½çœŒåã¨å¹´ã‚’æŠ½å‡ºãƒ»æ¤œè¨¼
        file_stem = json_path.stem  # tokyo_2023 or tokyo_2025_0715
        parts = file_stem.split('_')
        
        # åŸºæœ¬ãƒã‚§ãƒƒã‚¯: æœ€ä½2è¦ç´ å¿…è¦
        if len(parts) < 2:
            raise ValueError(f"Invalid filename format (need prefecture_year): {json_path.name}")
        
        # éƒ½çœŒåãƒã‚§ãƒƒã‚¯
        prefecture = parts[0]
        if prefecture not in self.VALID_PREFECTURES:
            raise ValueError(f"Invalid prefecture '{prefecture}'. Valid: {self.VALID_PREFECTURES}")
        
        # å¹´ãƒã‚§ãƒƒã‚¯
        year_str = parts[1]
        try:
            year = int(year_str)
            if not (2010 <= year <= 2100):
                raise ValueError(f"Year must be between 2010-2100: {year}")
        except ValueError:
            raise ValueError(f"Invalid year format '{year_str}': {json_path.name}")
        
        # æ—¥ä»˜ãƒã‚§ãƒƒã‚¯ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        date_part = None
        if len(parts) == 3:
            date_part = parts[2]
            # MMDDå½¢å¼ãƒã‚§ãƒƒã‚¯
            if len(date_part) != 4 or not date_part.isdigit():
                raise ValueError(f"Date must be MMDD format: {date_part}")
            
            # å®Ÿåœ¨æ—¥ä»˜ãƒã‚§ãƒƒã‚¯
            try:
                month = int(date_part[:2])
                day = int(date_part[2:])
                datetime(year, month, day)  # å®Ÿåœ¨æ—¥ä»˜ã‹ãƒã‚§ãƒƒã‚¯
            except ValueError:
                raise ValueError(f"Invalid date {year}-{date_part}: not a real date")
        elif len(parts) > 3:
            raise ValueError(f"Too many parts in filename: {json_path.name}")
        
        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
        if date_part:
            output_filename = f"{prefecture}_{year}_{date_part}.csv"
        else:
            output_filename = f"{prefecture}_{year}.csv"
        output_path = self.output_dir / output_filename
        
        logger.info(f"Converting {json_path.name} to {output_filename}")
        
        # JSONãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        hourly_data = data['hourly']
        times = hourly_data['time']
        temperatures = hourly_data['temperature_2m']
        humidity = hourly_data['relative_humidity_2m']
        precipitation = hourly_data['precipitation']
        weather_codes = hourly_data['weather_code']
        
        # äº‹å‰ã«ãƒ‡ãƒ¼ã‚¿å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        has_matching_data = False
        for i in range(len(times)):
            time_str = times[i]
            dt = datetime.fromisoformat(time_str)
            date_str = dt.strftime('%Y-%m-%d')
            if not date_filter or date_str == date_filter:
                has_matching_data = True
                break
        
        # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯å‡¦ç†çµ‚äº†
        if not has_matching_data:
            logger.info(f"No matching data found for date filter {date_filter} in {json_path.name}")
            return None
        
        # CSVå‡ºåŠ›
        converted_count = 0
        with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ
            writer.writerow([
                'prefecture', 'date', 'hour', 'temperature_2m', 
                'relative_humidity_2m', 'precipitation', 'weather_code'
            ])
            
            # ãƒ‡ãƒ¼ã‚¿è¡Œ
            for i in range(len(times)):
                # æ™‚åˆ»è§£æ (ä¾‹: 2023-01-01T00:00 -> 2023-01-01, 00)
                time_str = times[i]
                dt = datetime.fromisoformat(time_str)
                date_str = dt.strftime('%Y-%m-%d')
                hour_str = dt.strftime('%H')
                
                # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨ï¼ˆäº‹å‰ãƒã‚§ãƒƒã‚¯æ¸ˆã¿ãªã®ã§å¿…è¦ãªè¡Œã®ã¿å‡¦ç†ï¼‰
                if date_filter and date_str != date_filter:
                    continue
                
                # CSVè¡Œå‡ºåŠ›
                writer.writerow([
                    prefecture,
                    date_str,
                    hour_str,
                    temperatures[i],
                    humidity[i],
                    precipitation[i],
                    weather_codes[i]
                ])
                converted_count += 1
        
        logger.info(f"Converted {converted_count} records to {output_path}")
        return str(output_path)
    
    def process_directory(self, input_dir, date_filter=None):
        """
        ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬å¤‰æ›
        
        Args:
            input_dir (str): å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
            date_filter (str, optional): æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ (YYYY-MM-DDå½¢å¼)
            
        Returns:
            dict: å‡¦ç†çµæœ {'success': [...], 'failed': [...]}
        """
        input_path = Path(input_dir)
        if not input_path.exists():
            raise FileNotFoundError(f"Input directory not found: {input_dir}")
        
        # JSONãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
        json_files = list(input_path.glob("*.json"))
        if not json_files:
            logger.warning(f"No JSON files found in {input_dir}")
            return {'success': [], 'failed': []}
        
        logger.info(f"Found {len(json_files)} JSON files in {input_dir}")
        
        results = {'success': [], 'failed': []}
        
        for json_file in sorted(json_files):
            try:
                output_path = self.convert_json_to_csv(str(json_file), date_filter)
                if output_path:  # Noneã§ãªã„å ´åˆã®ã¿æˆåŠŸã¨ã—ã¦è¨˜éŒ²
                    results['success'].append({
                        'input': str(json_file),
                        'output': output_path
                    })
                # output_pathãŒNoneã®å ´åˆã¯ä½•ã‚‚è¨˜éŒ²ã—ãªã„ï¼ˆç©ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆã•ã‚Œãªã„ï¼‰
            except Exception as e:
                logger.error(f"Failed to convert {json_file}: {e}")
                results['failed'].append({
                    'input': str(json_file),
                    'error': str(e)
                })
        
        return results


def print_results(results):
    """å‡¦ç†çµæœã‚’è¡¨ç¤º"""
    success_count = len(results['success'])
    failed_count = len(results['failed'])
    
    print(f"\n{'='*60}")
    print("ğŸ“Š æ°—è±¡ãƒ‡ãƒ¼ã‚¿å¤‰æ›çµæœ")
    print('='*60)
    
    if results['success']:
        print(f"\nâœ… æˆåŠŸ: {success_count}ãƒ•ã‚¡ã‚¤ãƒ«")
        for item in results['success']:
            input_name = Path(item['input']).name
            output_name = Path(item['output']).name
            print(f"  {input_name} â†’ {output_name}")
    
    if results['failed']:
        print(f"\nâŒ å¤±æ•—: {failed_count}ãƒ•ã‚¡ã‚¤ãƒ«")
        for item in results['failed']:
            input_name = Path(item['input']).name
            print(f"  {input_name}: {item['error']}")
    
    if success_count == 0 and failed_count == 0:
        print("ğŸ“ å‡¦ç†å¯¾è±¡ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    
    print(f"\nğŸ“ˆ ç·åˆçµæœ: æˆåŠŸ{success_count}ä»¶ / å¤±æ•—{failed_count}ä»¶")
    print('='*60)


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    # ãƒ­ã‚°è¨­å®šã‚’åˆæœŸåŒ–
    setup_logging()
    
    parser = argparse.ArgumentParser(description='æ°—è±¡ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ (JSONâ†’CSV)')
    parser.add_argument('--input-dir', type=str, 
                       default='data/weather/raw/forecast',
                       help='å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: data/weather/raw/forecast)')
    parser.add_argument('--date', type=str,
                       help='ç‰¹å®šæ—¥ä»˜ã®ã¿å‡¦ç† (YYYY-MM-DDå½¢å¼)')
    parser.add_argument('--output-dir', type=str, default='data/weather/processed/forecast',
                       help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: data/weather/processed/forecast)')
    
    args = parser.parse_args()
    
    # æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œè¨¼
    if args.date:
        try:
            datetime.strptime(args.date, '%Y-%m-%d')
        except ValueError:
            print("âŒ ã‚¨ãƒ©ãƒ¼: æ—¥ä»˜ã¯YYYY-MM-DDå½¢å¼ã§å…¥åŠ›ã—ã¦ãã ã•ã„")
            return
    
    # ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼åˆæœŸåŒ–
    processor = WeatherProcessor(args.output_dir)
    
    print("ğŸš€ æ°—è±¡ãƒ‡ãƒ¼ã‚¿å¤‰æ›å‡¦ç†é–‹å§‹")
    print(f"ğŸ“‚ å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {args.input_dir}")
    print(f"ğŸ“‚ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {args.output_dir}")
    if args.date:
        print(f"ğŸ“… æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿: {args.date}")
    
    try:
        # å¤‰æ›å‡¦ç†å®Ÿè¡Œ
        results = processor.process_directory(args.input_dir, args.date)
        
        # çµæœè¡¨ç¤º
        print_results(results)
        
    except Exception as e:
        logger.error(f"Weather processing failed: {e}")
        print(f"ğŸ’¥ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    print("ğŸ æ°—è±¡ãƒ‡ãƒ¼ã‚¿å¤‰æ›å®Œäº†")


if __name__ == "__main__":
    main()